{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking an open-source ECG classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report benchmarks the difference in performance of an open-source ECG \n",
    "classification model on general population vs athletic population cohorts.\n",
    "\n",
    "The model selected was developed by researchers at Seoul National University \n",
    "for the 2020 PhysioNet Challenge. The paper describing their approach, \n",
    "\"Bag of Tricks for Electrocardiogram Classification With Deep Neural Networks\", \n",
    "is a good read for novice machine learning practitioners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaun/source/Thesis/PhysioNetChallenge2020/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Click to see packages imported\"\n",
    "import os\n",
    "import configparser\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import wfdb\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is /Users/shaun/source/Thesis/PhysioNetChallenge2020\n"
     ]
    }
   ],
   "source": [
    "#|include: false\n",
    "# If the current working directory is the nbs/ folder, change to the project \n",
    "# root directory instead.\n",
    "\n",
    "if Path.cwd().stem == \"nbs\":\n",
    "    os.chdir(Path.cwd().parent)\n",
    "print(f\"The current working directory is {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Click to see local packages imported\"\n",
    "from src.run_12ECG_classifier import load_12ECG_model, run_12ECG_classifier\n",
    "from src.data.util import get_all_records, get_predicted_findings, diagnosis_codes, codes_to_label_vector\n",
    "import src.data.norwegian as norwegian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets are located at /Users/shaun/source/Thesis/PhysioNetChallenge2020/data\n"
     ]
    }
   ],
   "source": [
    "#|include: false\n",
    "# Import configuration settings, like location of data directory.\n",
    "config = configparser.ConfigParser()\n",
    "if not Path(\"config.ini\").exists():\n",
    "    print(\"WARNING: Please generate a config.ini file by running scripts/get_datasets.py\")\n",
    "else:\n",
    "    config.read(\"config.ini\")\n",
    "    data_dir = Path((config[\"datasets\"][\"path\"])).expanduser()\n",
    "    print(f\"Datasets are located at {data_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|include: false\n",
    "# Extract source code and weights from zip file\n",
    "# We only need the weights\n",
    "model_zip_dir = data_dir / \"challenge-2020\" / \"1.0.2\" / \"sources\"\n",
    "with ZipFile(model_zip_dir / \"DSAIL_SNU.zip\", 'r') as zip:\n",
    "    zip.extractall(model_zip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shaun/source/Thesis/PhysioNetChallenge2020/checkpoints/original\n",
      "config directory already exists\n"
     ]
    }
   ],
   "source": [
    "#|include: false\n",
    "team_dir = model_zip_dir / \"DSAIL_SNU\" / \"PhysioNetChallenge2020_DSAIL_SNU7\"\n",
    "\n",
    "\"\"\"\n",
    "To make it easier to run and modify the model, we'll copy the source code and \n",
    "model weights to the root of our git repo.\n",
    "\n",
    "First, we'll copy the following directories from `model_dir` to the root of our git repo:\n",
    "- `config` (includes confusion matrix weights, settings for data preprocessing etc.)\n",
    "- `output_training_directory` (checkpoints for model weights)\n",
    "\"\"\"\n",
    "\n",
    "result = shutil.copytree(team_dir / \"output_training_directory\", Path.cwd() / \"checkpoints\" / \"original\", dirs_exist_ok=True)\n",
    "print(result)\n",
    "\n",
    "# Don't want to overwrite if we make changes to config later on.\n",
    "try:\n",
    "    shutil.copytree(team_dir / \"config\", Path.cwd() / \"config\", dirs_exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"config directory already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = Path.cwd() / \"checkpoints\" / \"original\"\n",
    "config_dir = Path.cwd() / \"config\"\n",
    "# input_dir = Path.cwd() / \"data\" / \"challenge-2020\" / \"1.0.2\" / \"training\" / \"georgia\" / \"g1\"\n",
    "\n",
    "benchmark_dir = Path.cwd() / \"data\" / \"benchmark\"\n",
    "if not benchmark_dir.exists():\n",
    "    benchmark_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shaun/source/Thesis/PhysioNetChallenge2020/data/benchmark/norwegian-athlete-ecg already exists. Benchmark has already been run.\n"
     ]
    }
   ],
   "source": [
    "# Benchmark: norwegian-athlete-ecg\n",
    "input_dir = Path.cwd() / \"data\" / \"norwegian-athlete-ecg\" / \"1.0.0\"\n",
    "output_dir = benchmark_dir / \"norwegian-athlete-ecg\"\n",
    "\n",
    "if output_dir.exists():\n",
    "    print(f\"{output_dir} already exists. Benchmark has already been run.\")\n",
    "else:\n",
    "    # Run benchmark using modified PhysioNet Challenge 2020 driver.py\n",
    "    !python PhysioNet2020_driver.py {weights_dir} {config_dir} {input_dir} {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shaun/source/Thesis/PhysioNetChallenge2020/data/benchmark/georgia/g1 already exists. Benchmark has already been run.\n"
     ]
    }
   ],
   "source": [
    "# Benchmark: georgia, subset g1\n",
    "input_dir = Path.cwd() / \"data\" / \"challenge-2020\" / \"1.0.2\" / \"training\" / \"georgia\" / \"g1\"\n",
    "output_dir = benchmark_dir / \"georgia\" / \"g1\"\n",
    "\n",
    "if output_dir.exists():\n",
    "    print(f\"{output_dir} already exists. Benchmark has already been run.\")\n",
    "else:\n",
    "    # Run benchmark using modified PhysioNet Challenge 2020 driver.py\n",
    "    output_dir.mkdir(parents=True)\n",
    "    !python PhysioNet2020_driver.py {weights_dir} {config_dir} {input_dir} {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shaun/source/Thesis/PhysioNetChallenge2020/data/benchmark/cpsc_2018/g1 already exists. Benchmark has already been run.\n"
     ]
    }
   ],
   "source": [
    "# Benchmark: CPSC 2018, subset g1\n",
    "input_dir = Path.cwd() / \"data\" / \"challenge-2020\" / \"1.0.2\" / \"training\" / \"cpsc_2018\" / \"g1\"\n",
    "output_dir = benchmark_dir / \"cpsc_2018\" / \"g1\"\n",
    "\n",
    "if output_dir.exists():\n",
    "    print(f\"{output_dir} already exists. Benchmark has already been run.\")\n",
    "else:\n",
    "    # Run benchmark using modified PhysioNet Challenge 2020 driver.py\n",
    "    output_dir.mkdir(parents=True)\n",
    "    !python PhysioNet2020_driver.py {weights_dir} {config_dir} {input_dir} {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 12ECG model...\n",
      "Extracting 12ECG features...\n",
      "    1/516...\n",
      "    2/516...\n",
      "    3/516...\n",
      "    4/516...\n",
      "    5/516...\n",
      "    6/516...\n",
      "    7/516...\n",
      "    8/516...\n",
      "    9/516...\n",
      "    10/516...\n",
      "    11/516...\n",
      "    12/516...\n",
      "    13/516...\n",
      "    14/516...\n",
      "    15/516...\n",
      "    16/516...\n",
      "    17/516...\n",
      "    18/516...\n",
      "    19/516...\n",
      "    20/516...\n",
      "    21/516...\n",
      "    22/516...\n",
      "    23/516...\n",
      "    24/516...\n",
      "    25/516...\n",
      "    26/516...\n",
      "    27/516...\n",
      "    28/516...\n",
      "    29/516...\n",
      "    30/516...\n",
      "    31/516...\n",
      "    32/516...\n",
      "    33/516...\n",
      "    34/516...\n",
      "    35/516...\n",
      "    36/516...\n",
      "    37/516...\n",
      "    38/516...\n",
      "    39/516...\n",
      "    40/516...\n",
      "    41/516...\n",
      "    42/516...\n",
      "    43/516...\n",
      "    44/516...\n",
      "    45/516...\n",
      "    46/516...\n",
      "    47/516...\n",
      "    48/516...\n",
      "    49/516...\n",
      "    50/516...\n",
      "    51/516...\n",
      "    52/516...\n",
      "    53/516...\n",
      "    54/516...\n",
      "    55/516...\n",
      "    56/516...\n",
      "    57/516...\n",
      "    58/516...\n",
      "    59/516...\n",
      "    60/516...\n",
      "    61/516...\n",
      "    62/516...\n",
      "    63/516...\n",
      "    64/516...\n",
      "    65/516...\n",
      "    66/516...\n",
      "    67/516...\n",
      "    68/516...\n",
      "    69/516...\n",
      "    70/516...\n",
      "    71/516...\n",
      "    72/516...\n",
      "    73/516...\n",
      "    74/516...\n",
      "    75/516...\n",
      "    76/516...\n",
      "    77/516...\n",
      "    78/516...\n",
      "    79/516...\n",
      "    80/516...\n",
      "    81/516...\n",
      "    82/516...\n",
      "    83/516...\n",
      "    84/516...\n",
      "    85/516...\n",
      "    86/516...\n",
      "    87/516...\n",
      "    88/516...\n",
      "    89/516...\n",
      "    90/516...\n",
      "    91/516...\n",
      "    92/516...\n",
      "    93/516...\n",
      "    94/516...\n",
      "    95/516...\n",
      "    96/516...\n",
      "    97/516...\n",
      "    98/516...\n",
      "    99/516...\n",
      "    100/516...\n",
      "    101/516...\n",
      "    102/516...\n",
      "    103/516...\n",
      "    104/516...\n",
      "    105/516...\n",
      "    106/516...\n",
      "    107/516...\n",
      "    108/516...\n",
      "    109/516...\n",
      "    110/516...\n",
      "    111/516...\n",
      "    112/516...\n",
      "    113/516...\n",
      "    114/516...\n",
      "    115/516...\n",
      "    116/516...\n",
      "    117/516...\n",
      "    118/516...\n",
      "    119/516...\n",
      "    120/516...\n",
      "    121/516...\n",
      "    122/516...\n",
      "    123/516...\n",
      "    124/516...\n",
      "    125/516...\n",
      "    126/516...\n",
      "    127/516...\n",
      "    128/516...\n",
      "    129/516...\n",
      "    130/516...\n",
      "    131/516...\n",
      "    132/516...\n",
      "    133/516...\n",
      "    134/516...\n",
      "    135/516...\n",
      "    136/516...\n",
      "    137/516...\n",
      "    138/516...\n",
      "    139/516...\n",
      "    140/516...\n",
      "    141/516...\n",
      "    142/516...\n",
      "    143/516...\n",
      "    144/516...\n",
      "    145/516...\n",
      "    146/516...\n",
      "    147/516...\n",
      "    148/516...\n",
      "    149/516...\n",
      "    150/516...\n",
      "    151/516...\n",
      "    152/516...\n",
      "    153/516...\n",
      "    154/516...\n",
      "    155/516...\n",
      "    156/516...\n",
      "    157/516...\n",
      "    158/516...\n",
      "    159/516...\n",
      "    160/516...\n",
      "    161/516...\n",
      "    162/516...\n",
      "    163/516...\n",
      "    164/516...\n",
      "    165/516...\n",
      "    166/516...\n",
      "    167/516...\n",
      "    168/516...\n",
      "    169/516...\n",
      "    170/516...\n",
      "    171/516...\n",
      "    172/516...\n",
      "    173/516...\n",
      "    174/516...\n",
      "    175/516...\n",
      "    176/516...\n",
      "    177/516...\n",
      "    178/516...\n",
      "    179/516...\n",
      "    180/516...\n",
      "    181/516...\n",
      "    182/516...\n",
      "    183/516...\n",
      "    184/516...\n",
      "    185/516...\n",
      "    186/516...\n",
      "    187/516...\n",
      "    188/516...\n",
      "    189/516...\n",
      "    190/516...\n",
      "    191/516...\n",
      "    192/516...\n",
      "    193/516...\n",
      "    194/516...\n",
      "    195/516...\n",
      "    196/516...\n",
      "    197/516...\n",
      "    198/516...\n",
      "    199/516...\n",
      "    200/516...\n",
      "    201/516...\n",
      "    202/516...\n",
      "    203/516...\n",
      "    204/516...\n",
      "    205/516...\n",
      "    206/516...\n",
      "    207/516...\n",
      "    208/516...\n",
      "    209/516...\n",
      "    210/516...\n",
      "    211/516...\n",
      "    212/516...\n",
      "    213/516...\n",
      "    214/516...\n",
      "    215/516...\n",
      "    216/516...\n",
      "    217/516...\n",
      "    218/516...\n",
      "    219/516...\n",
      "    220/516...\n",
      "    221/516...\n",
      "    222/516...\n",
      "    223/516...\n",
      "    224/516...\n",
      "    225/516...\n",
      "    226/516...\n",
      "    227/516...\n",
      "    228/516...\n",
      "    229/516...\n",
      "    230/516...\n",
      "    231/516...\n",
      "    232/516...\n",
      "    233/516...\n",
      "    234/516...\n",
      "    235/516...\n",
      "    236/516...\n",
      "    237/516...\n",
      "    238/516...\n",
      "    239/516...\n",
      "    240/516...\n",
      "    241/516...\n",
      "    242/516...\n",
      "    243/516...\n",
      "    244/516...\n",
      "    245/516...\n",
      "    246/516...\n",
      "    247/516...\n",
      "    248/516...\n",
      "    249/516...\n",
      "    250/516...\n",
      "    251/516...\n",
      "    252/516...\n",
      "    253/516...\n",
      "    254/516...\n",
      "    255/516...\n",
      "    256/516...\n",
      "    257/516...\n",
      "    258/516...\n",
      "    259/516...\n",
      "    260/516...\n",
      "    261/516...\n",
      "    262/516...\n",
      "    263/516...\n",
      "    264/516...\n",
      "    265/516...\n",
      "    266/516...\n",
      "    267/516...\n",
      "    268/516...\n",
      "    269/516...\n",
      "    270/516...\n",
      "    271/516...\n",
      "    272/516...\n",
      "    273/516...\n",
      "    274/516...\n",
      "    275/516...\n",
      "    276/516...\n",
      "    277/516...\n",
      "    278/516...\n",
      "    279/516...\n",
      "    280/516...\n",
      "    281/516...\n",
      "    282/516...\n",
      "    283/516...\n",
      "    284/516...\n",
      "    285/516...\n",
      "    286/516...\n",
      "    287/516...\n",
      "    288/516...\n",
      "    289/516...\n",
      "    290/516...\n",
      "    291/516...\n",
      "    292/516...\n",
      "    293/516...\n",
      "    294/516...\n",
      "    295/516...\n",
      "    296/516...\n",
      "    297/516...\n",
      "    298/516...\n",
      "    299/516...\n",
      "    300/516...\n",
      "    301/516...\n",
      "    302/516...\n",
      "    303/516...\n",
      "    304/516...\n",
      "    305/516...\n",
      "    306/516...\n",
      "    307/516...\n",
      "    308/516...\n",
      "    309/516...\n",
      "    310/516...\n",
      "    311/516...\n",
      "    312/516...\n",
      "    313/516...\n",
      "    314/516...\n",
      "    315/516...\n",
      "    316/516...\n",
      "    317/516...\n",
      "    318/516...\n",
      "    319/516...\n",
      "    320/516...\n",
      "    321/516...\n",
      "    322/516...\n",
      "    323/516...\n",
      "    324/516...\n",
      "    325/516...\n",
      "    326/516...\n",
      "    327/516...\n",
      "    328/516...\n",
      "    329/516...\n",
      "    330/516...\n",
      "    331/516...\n",
      "    332/516...\n",
      "    333/516...\n",
      "    334/516...\n",
      "    335/516...\n",
      "    336/516...\n",
      "    337/516...\n",
      "    338/516...\n",
      "    339/516...\n",
      "    340/516...\n",
      "    341/516...\n",
      "    342/516...\n",
      "    343/516...\n",
      "    344/516...\n",
      "    345/516...\n",
      "    346/516...\n",
      "    347/516...\n",
      "    348/516...\n",
      "    349/516...\n",
      "    350/516...\n",
      "    351/516...\n",
      "    352/516...\n",
      "    353/516...\n",
      "    354/516...\n",
      "    355/516...\n",
      "    356/516...\n",
      "    357/516...\n",
      "    358/516...\n",
      "    359/516...\n",
      "    360/516...\n",
      "    361/516...\n",
      "    362/516...\n",
      "    363/516...\n",
      "    364/516...\n",
      "    365/516...\n",
      "    366/516...\n",
      "    367/516...\n",
      "    368/516...\n",
      "    369/516...\n",
      "    370/516...\n",
      "    371/516...\n",
      "    372/516...\n",
      "    373/516...\n",
      "    374/516...\n",
      "    375/516...\n",
      "    376/516...\n",
      "    377/516...\n",
      "    378/516...\n",
      "    379/516...\n",
      "    380/516...\n",
      "    381/516...\n",
      "    382/516...\n",
      "    383/516...\n",
      "    384/516...\n",
      "    385/516...\n",
      "    386/516...\n",
      "    387/516...\n",
      "    388/516...\n",
      "    389/516...\n",
      "    390/516...\n",
      "    391/516...\n",
      "    392/516...\n",
      "    393/516...\n",
      "    394/516...\n",
      "    395/516...\n",
      "    396/516...\n",
      "    397/516...\n",
      "    398/516...\n",
      "    399/516...\n",
      "    400/516...\n",
      "    401/516...\n",
      "    402/516...\n",
      "    403/516...\n",
      "    404/516...\n",
      "    405/516...\n",
      "    406/516...\n",
      "    407/516...\n",
      "    408/516...\n",
      "    409/516...\n",
      "    410/516...\n",
      "    411/516...\n",
      "    412/516...\n",
      "    413/516...\n",
      "    414/516...\n",
      "    415/516...\n",
      "    416/516...\n",
      "    417/516...\n",
      "    418/516...\n",
      "    419/516...\n",
      "    420/516...\n",
      "    421/516...\n",
      "    422/516...\n",
      "    423/516...\n",
      "    424/516...\n",
      "    425/516...\n",
      "    426/516...\n",
      "    427/516...\n",
      "    428/516...\n",
      "    429/516...\n",
      "    430/516...\n",
      "    431/516...\n",
      "    432/516...\n",
      "    433/516...\n",
      "    434/516...\n",
      "    435/516...\n",
      "    436/516...\n",
      "    437/516...\n",
      "    438/516...\n",
      "    439/516...\n",
      "    440/516...\n",
      "    441/516...\n",
      "    442/516...\n",
      "    443/516...\n",
      "    444/516...\n",
      "    445/516...\n",
      "    446/516...\n",
      "    447/516...\n",
      "    448/516...\n",
      "    449/516...\n",
      "    450/516...\n",
      "    451/516...\n",
      "    452/516...\n",
      "    453/516...\n",
      "    454/516...\n",
      "    455/516...\n",
      "    456/516...\n",
      "    457/516...\n",
      "    458/516...\n",
      "    459/516...\n",
      "    460/516...\n",
      "    461/516...\n",
      "    462/516...\n",
      "    463/516...\n",
      "    464/516...\n",
      "    465/516...\n",
      "    466/516...\n",
      "    467/516...\n",
      "    468/516...\n",
      "    469/516...\n",
      "    470/516...\n",
      "    471/516...\n",
      "    472/516...\n",
      "    473/516...\n",
      "    474/516...\n",
      "    475/516...\n",
      "    476/516...\n",
      "    477/516...\n",
      "    478/516...\n",
      "    479/516...\n",
      "    480/516...\n",
      "    481/516...\n",
      "    482/516...\n",
      "    483/516...\n",
      "    484/516...\n",
      "    485/516...\n",
      "    486/516...\n",
      "    487/516...\n",
      "    488/516...\n",
      "    489/516...\n",
      "    490/516...\n",
      "    491/516...\n",
      "    492/516...\n",
      "    493/516...\n",
      "    494/516...\n",
      "    495/516...\n",
      "    496/516...\n",
      "    497/516...\n",
      "    498/516...\n",
      "    499/516...\n",
      "    500/516...\n",
      "    501/516...\n",
      "    502/516...\n",
      "    503/516...\n",
      "    504/516...\n",
      "    505/516...\n",
      "    506/516...\n",
      "    507/516...\n",
      "    508/516...\n",
      "    509/516...\n",
      "    510/516...\n",
      "    511/516...\n",
      "    512/516...\n",
      "    513/516...\n",
      "    514/516...\n",
      "    515/516...\n",
      "    516/516...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Benchmark: PTB (excluded from training set)\n",
    "input_dir = Path.cwd() / \"data\" / \"challenge-2020\" / \"1.0.2\" / \"training\" / \"ptb\" / \"g1\"\n",
    "output_dir = benchmark_dir / \"ptb\" / \"g1\"\n",
    "\n",
    "if output_dir.exists():\n",
    "    print(f\"{output_dir} already exists. Benchmark has already been run.\")\n",
    "else:\n",
    "    # Run benchmark using modified PhysioNet Challenge 2020 driver.py\n",
    "    output_dir.mkdir(parents=True)\n",
    "    !python PhysioNet2020_driver.py {weights_dir} {config_dir} {input_dir} {output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only care about a subset of diagnosis labels which are easily misdiagnosed in athletes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sinus_labels = [426177001, 426783006, 427084000, 427393009]\n",
    "sinus_labels = [426177001, 426783006]       # Bradycardia or Normal\n",
    "rbbb_labels = [713427006, 713426002]        # Incomplete RBBB, Complete RBBB\n",
    "# won't do t-wave inversion, because no output for lead number provided.\n",
    "athlete_labels = sinus_labels + rbbb_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring (PhysioNet Challenge datasets)\n",
    "# input_dir = Path.cwd() / \"data\" / \"challenge-2020\" / \"1.0.2\" / \"training\" / \"georgia\" / \"g1\"\n",
    "# output_dir = benchmark_dir / \"georgia\" / \"g1\"\n",
    "# input_dir = Path.cwd() / \"data\" / \"challenge-2020\" / \"1.0.2\" / \"training\" / \"cpsc_2018\" / \"g1\"\n",
    "# output_dir = benchmark_dir / \"cpsc_2018\" / \"g1\"\n",
    "input_dir = Path.cwd() / \"data\" / \"challenge-2020\" / \"1.0.2\" / \"training\" / \"ptb\" / \"g1\"\n",
    "output_dir = benchmark_dir / \"ptb\" / \"g1\"\n",
    "\n",
    "total_confusion = np.zeros((2,2), dtype=int)\n",
    "for entry in get_all_records(input_dir):\n",
    "    # Actual labels from PhysioNet Challenge dataset\n",
    "    record = wfdb.rdrecord(input_dir / entry)\n",
    "    comment_dx = record.comments[2].split(': ')[1]\n",
    "    actual_findings = list(map(int, comment_dx.split(',')))\n",
    "    actual_labels = codes_to_label_vector(actual_findings, athlete_labels)\n",
    "\n",
    "    # Predicted label from model\n",
    "    file = output_dir / (entry+'.csv')\n",
    "    predicted_findings = get_predicted_findings(file)\n",
    "    predicted_labels = codes_to_label_vector(predicted_findings, athlete_labels)\n",
    "\n",
    "    # Hack: If no sinus rhythm findings, assume normal sinus rhythm (426783006)\n",
    "    if sum(actual_labels) == 0:\n",
    "        actual_labels[1] = 1\n",
    "    if sum(predicted_labels) == 0:\n",
    "        predicted_labels[1] = 1\n",
    "    \n",
    "    # Calculate confusion matrix for entry, add to total\n",
    "    total_confusion += confusion_matrix(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classifier_metrics(tn, fp, fn, tp):\n",
    "    P = tp + fn\n",
    "    N = fp + tn\n",
    "    print(\"Population\")\n",
    "    print(\"----------\")\n",
    "    print(f\"Total population: {P+N}\")\n",
    "    print(f\"Positive: {P}\")\n",
    "    print(f\"Negative: {N}\\n\")\n",
    "\n",
    "    acc = (tp + tn) / (P+N)\n",
    "    ppv = tp / (tp + fp)\n",
    "    f1 = 2 * tp / (2*tp + fp + fn)\n",
    "    print(\"Performance\")\n",
    "    print(\"-----------\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Precision: {ppv}\")\n",
    "    print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1467,   81],\n",
       "       [  58,  458]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population\n",
      "----------\n",
      "Total population: 2064\n",
      "Positive: 516\n",
      "Negative: 1548\n",
      "\n",
      "Performance\n",
      "-----------\n",
      "Accuracy: 0.9326550387596899\n",
      "Precision: 0.849721706864564\n",
      "F1-Score: 0.8682464454976303\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = total_confusion.ravel()\n",
    "print_classifier_metrics(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring (norwegian-athlete-ecg)\n",
    "input_dir = Path.cwd() / \"data\" / \"norwegian-athlete-ecg\" / \"1.0.0\"\n",
    "output_dir = benchmark_dir / \"norwegian-athlete-ecg\"\n",
    "\n",
    "total_confusion = np.zeros((2,2), dtype=int)\n",
    "for entry in get_all_records(input_dir):\n",
    "    # Actual labels from dataset\n",
    "    record = wfdb.rdrecord(input_dir / entry)\n",
    "    comments_c = record.comments[1]\n",
    "    findings_c = norwegian.extract_findings(comments_c)\n",
    "\n",
    "    actual_findings = norwegian.classify_relevant_findings(findings_c)\n",
    "    actual_labels = codes_to_label_vector(actual_findings, athlete_labels)\n",
    "\n",
    "    # Predicted label from model\n",
    "    file = output_dir / (entry+'.csv')\n",
    "    predicted_findings = get_predicted_findings(file)\n",
    "    predicted_labels = codes_to_label_vector(predicted_findings, athlete_labels)\n",
    "\n",
    "    # Hack: If no sinus rhythm findings, assume normal sinus rhythm (426783006)\n",
    "    if sum(actual_labels) == 0:\n",
    "        actual_labels[1] = 1\n",
    "    if sum(predicted_labels) == 0:\n",
    "        predicted_labels[1] = 1\n",
    "    \n",
    "    # Calculate confusion matrix for entry, add to total\n",
    "    total_confusion += confusion_matrix(actual_labels, predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62, 19],\n",
       "       [17, 14]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population\n",
      "----------\n",
      "Total population: 112\n",
      "Positive: 31\n",
      "Negative: 81\n",
      "\n",
      "Performance\n",
      "-----------\n",
      "Accuracy: 0.6785714285714286\n",
      "Precision: 0.42424242424242425\n",
      "F1-Score: 0.4375\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = total_confusion.ravel()\n",
    "print_classifier_metrics(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Collate diagnosis results into a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse engineering the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../media/DSAIL_model-architecture.jpg)\n",
    "\n",
    "***Figure: ResNet architecture***\n",
    "\n",
    "Ensemble of 10 neural networks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DSAIL = load_12ECG_model(weights_dir, config_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dsail.config.DataConfig'>\n",
      "<class 'dsail.config.PreprocessConfig'>\n",
      "<class 'dsail.config.RunConfig'>\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for thing in model_DSAIL:\n",
    "    print(type(thing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n"
     ]
    }
   ],
   "source": [
    "for net in model_DSAIL[3]:\n",
    "    print(type(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.bn1.running_mean\n",
      "layer1.0.bn1.running_var\n",
      "layer1.0.bn1.num_batches_tracked\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.0.bn2.running_mean\n",
      "layer1.0.bn2.running_var\n",
      "layer1.0.bn2.num_batches_tracked\n",
      "layer1.0.conv1.1.weight\n",
      "layer1.0.conv2.1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.bn1.running_mean\n",
      "layer1.1.bn1.running_var\n",
      "layer1.1.bn1.num_batches_tracked\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer1.1.bn2.running_mean\n",
      "layer1.1.bn2.running_var\n",
      "layer1.1.bn2.num_batches_tracked\n",
      "layer1.1.conv1.1.weight\n",
      "layer1.1.conv2.1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.bn1.running_mean\n",
      "layer2.0.bn1.running_var\n",
      "layer2.0.bn1.num_batches_tracked\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.bn2.running_mean\n",
      "layer2.0.bn2.running_var\n",
      "layer2.0.bn2.num_batches_tracked\n",
      "layer2.0.conv1.1.weight\n",
      "layer2.0.conv2.1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.bn1.running_mean\n",
      "layer2.1.bn1.running_var\n",
      "layer2.1.bn1.num_batches_tracked\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer2.1.bn2.running_mean\n",
      "layer2.1.bn2.running_var\n",
      "layer2.1.bn2.num_batches_tracked\n",
      "layer2.1.conv1.1.weight\n",
      "layer2.1.conv2.1.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.bn1.running_mean\n",
      "layer3.0.bn1.running_var\n",
      "layer3.0.bn1.num_batches_tracked\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.bn2.running_mean\n",
      "layer3.0.bn2.running_var\n",
      "layer3.0.bn2.num_batches_tracked\n",
      "layer3.0.conv1.1.weight\n",
      "layer3.0.conv2.1.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.bn1.running_mean\n",
      "layer3.1.bn1.running_var\n",
      "layer3.1.bn1.num_batches_tracked\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer3.1.bn2.running_mean\n",
      "layer3.1.bn2.running_var\n",
      "layer3.1.bn2.num_batches_tracked\n",
      "layer3.1.conv1.1.weight\n",
      "layer3.1.conv2.1.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.bn1.running_mean\n",
      "layer4.0.bn1.running_var\n",
      "layer4.0.bn1.num_batches_tracked\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.bn2.running_mean\n",
      "layer4.0.bn2.running_var\n",
      "layer4.0.bn2.num_batches_tracked\n",
      "layer4.0.conv1.1.weight\n",
      "layer4.0.conv2.1.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.bn1.running_mean\n",
      "layer4.1.bn1.running_var\n",
      "layer4.1.bn1.num_batches_tracked\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "layer4.1.bn2.running_mean\n",
      "layer4.1.bn2.running_var\n",
      "layer4.1.bn2.num_batches_tracked\n",
      "layer4.1.conv1.1.weight\n",
      "layer4.1.conv2.1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "bn1.running_mean\n",
      "bn1.running_var\n",
      "bn1.num_batches_tracked\n",
      "linear.weight\n",
      "linear.bias\n"
     ]
    }
   ],
   "source": [
    "for state in net.state_dict():\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG_model(\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(12, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "        (1): Conv1d(32, 64, kernel_size=(11,), stride=(4,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "        (1): Conv1d(64, 128, kernel_size=(11,), stride=(4,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "        (1): Conv1d(128, 256, kernel_size=(11,), stride=(4,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (linear): Linear(in_features=256, out_features=24, bias=True)\n",
      ")\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(12, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(12, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (1): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      ")\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "***\n",
      "BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential()\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "***\n",
      "BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential()\n",
      "***\n",
      "Sequential(\n",
      "  (0): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "      (1): Conv1d(32, 64, kernel_size=(11,), stride=(4,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      ")\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "    (1): Conv1d(32, 64, kernel_size=(11,), stride=(4,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential(\n",
      "    (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "***\n",
      "BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "  (1): Conv1d(32, 64, kernel_size=(11,), stride=(4,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(3, 4), value=0)\n",
      "***\n",
      "Conv1d(32, 64, kernel_size=(11,), stride=(4,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "***\n",
      "MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "***\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential()\n",
      "***\n",
      "Sequential(\n",
      "  (0): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "      (1): Conv1d(64, 128, kernel_size=(11,), stride=(4,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      ")\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "    (1): Conv1d(64, 128, kernel_size=(11,), stride=(4,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential(\n",
      "    (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "***\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "  (1): Conv1d(64, 128, kernel_size=(11,), stride=(4,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(3, 4), value=0)\n",
      "***\n",
      "Conv1d(64, 128, kernel_size=(11,), stride=(4,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "***\n",
      "MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "***\n",
      "BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential()\n",
      "***\n",
      "Sequential(\n",
      "  (0): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "      (1): Conv1d(128, 256, kernel_size=(11,), stride=(4,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      ")\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "    (1): Conv1d(128, 256, kernel_size=(11,), stride=(4,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential(\n",
      "    (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "***\n",
      "BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "  (1): Conv1d(128, 256, kernel_size=(11,), stride=(4,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(3, 4), value=0)\n",
      "***\n",
      "Conv1d(128, 256, kernel_size=(11,), stride=(4,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "***\n",
      "MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "***\n",
      "BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential()\n",
      "***\n",
      "BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "AdaptiveMaxPool1d(output_size=1)\n",
      "***\n",
      "Linear(in_features=256, out_features=24, bias=True)\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "for module in net.modules():\n",
    "    print(module)\n",
    "    print(\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ECG_model                                --\n",
       "Sequential: 1-1                        --\n",
       "    ConstantPad1d: 2-1                --\n",
       "    Conv1d: 2-2                       4,224\n",
       "Sequential: 1-2                        --\n",
       "    ResNet_Basic_Block: 2-3           --\n",
       "        BatchNorm1d: 3-1             64\n",
       "        BatchNorm1d: 3-2             64\n",
       "        ReLU: 3-3                    --\n",
       "        Dropout: 3-4                 --\n",
       "        Sequential: 3-5              11,264\n",
       "        Sequential: 3-6              11,264\n",
       "        Sequential: 3-7              --\n",
       "    ResNet_Basic_Block: 2-4           --\n",
       "        BatchNorm1d: 3-8             64\n",
       "        BatchNorm1d: 3-9             64\n",
       "        ReLU: 3-10                   --\n",
       "        Dropout: 3-11                --\n",
       "        Sequential: 3-12             11,264\n",
       "        Sequential: 3-13             11,264\n",
       "        Sequential: 3-14             --\n",
       "Sequential: 1-3                        --\n",
       "    ResNet_Basic_Block: 2-5           --\n",
       "        BatchNorm1d: 3-15            64\n",
       "        BatchNorm1d: 3-16            128\n",
       "        ReLU: 3-17                   --\n",
       "        Dropout: 3-18                --\n",
       "        Sequential: 3-19             22,528\n",
       "        Sequential: 3-20             45,056\n",
       "        Sequential: 3-21             --\n",
       "    ResNet_Basic_Block: 2-6           --\n",
       "        BatchNorm1d: 3-22            128\n",
       "        BatchNorm1d: 3-23            128\n",
       "        ReLU: 3-24                   --\n",
       "        Dropout: 3-25                --\n",
       "        Sequential: 3-26             45,056\n",
       "        Sequential: 3-27             45,056\n",
       "        Sequential: 3-28             --\n",
       "Sequential: 1-4                        --\n",
       "    ResNet_Basic_Block: 2-7           --\n",
       "        BatchNorm1d: 3-29            128\n",
       "        BatchNorm1d: 3-30            256\n",
       "        ReLU: 3-31                   --\n",
       "        Dropout: 3-32                --\n",
       "        Sequential: 3-33             90,112\n",
       "        Sequential: 3-34             180,224\n",
       "        Sequential: 3-35             --\n",
       "    ResNet_Basic_Block: 2-8           --\n",
       "        BatchNorm1d: 3-36            256\n",
       "        BatchNorm1d: 3-37            256\n",
       "        ReLU: 3-38                   --\n",
       "        Dropout: 3-39                --\n",
       "        Sequential: 3-40             180,224\n",
       "        Sequential: 3-41             180,224\n",
       "        Sequential: 3-42             --\n",
       "Sequential: 1-5                        --\n",
       "    ResNet_Basic_Block: 2-9           --\n",
       "        BatchNorm1d: 3-43            256\n",
       "        BatchNorm1d: 3-44            512\n",
       "        ReLU: 3-45                   --\n",
       "        Dropout: 3-46                --\n",
       "        Sequential: 3-47             360,448\n",
       "        Sequential: 3-48             720,896\n",
       "        Sequential: 3-49             --\n",
       "    ResNet_Basic_Block: 2-10          --\n",
       "        BatchNorm1d: 3-50            512\n",
       "        BatchNorm1d: 3-51            512\n",
       "        ReLU: 3-52                   --\n",
       "        Dropout: 3-53                --\n",
       "        Sequential: 3-54             720,896\n",
       "        Sequential: 3-55             720,896\n",
       "        Sequential: 3-56             --\n",
       "BatchNorm1d: 1-6                       512\n",
       "ReLU: 1-7                              --\n",
       "Dropout: 1-8                           --\n",
       "AdaptiveMaxPool1d: 1-9                 --\n",
       "Linear: 1-10                           6,168\n",
       "=================================================================\n",
       "Total params: 3,370,968\n",
       "Trainable params: 3,370,968\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying model weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
