{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking an open-source ECG classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report benchmarks the difference in performance of an open-source ECG \n",
    "classification model on general population vs athletic population cohorts.\n",
    "\n",
    "The model selected was developed by researchers at Seoul National University \n",
    "for the 2020 PhysioNet Challenge. The paper describing their approach, \n",
    "\"Bag of Tricks for Electrocardiogram Classification With Deep Neural Networks\", \n",
    "is a good read for novice machine learning practitioners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaun/source/Thesis/PhysioNetChallenge2020/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Click to see packages imported\"\n",
    "import os\n",
    "import configparser\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import wfdb\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is /Users/shaun/source/Thesis/PhysioNetChallenge2020\n"
     ]
    }
   ],
   "source": [
    "#|include: false\n",
    "# If the current working directory is the nbs/ folder, change to the project \n",
    "# root directory instead.\n",
    "\n",
    "if Path.cwd().stem == \"nbs\":\n",
    "    os.chdir(Path.cwd().parent)\n",
    "print(f\"The current working directory is {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Click to see local packages imported\"\n",
    "from src.run_12ECG_classifier import load_12ECG_model, run_12ECG_classifier\n",
    "from src.data.util import get_all_records, get_predicted_findings, diagnosis_codes, codes_to_label_vector\n",
    "import src.data.norwegian as norwegian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets are located at /Users/shaun/source/Thesis/PhysioNetChallenge2020/data\n"
     ]
    }
   ],
   "source": [
    "#|include: false\n",
    "# Import configuration settings, like location of data directory.\n",
    "config = configparser.ConfigParser()\n",
    "if not Path(\"config.ini\").exists():\n",
    "    print(\"WARNING: Please generate a config.ini file by running scripts/get_datasets.py\")\n",
    "else:\n",
    "    config.read(\"config.ini\")\n",
    "    data_dir = Path((config[\"datasets\"][\"path\"])).expanduser()\n",
    "    print(f\"Datasets are located at {data_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|include: false\n",
    "# Extract source code and weights from zip file\n",
    "# We only need the weights\n",
    "model_zip_dir = data_dir / \"challenge-2020\" / \"1.0.2\" / \"sources\"\n",
    "with ZipFile(model_zip_dir / \"DSAIL_SNU.zip\", 'r') as zip:\n",
    "    zip.extractall(model_zip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shaun/source/Thesis/PhysioNetChallenge2020/checkpoints/original\n",
      "config directory already exists\n"
     ]
    }
   ],
   "source": [
    "#|include: false\n",
    "team_dir = model_zip_dir / \"DSAIL_SNU\" / \"PhysioNetChallenge2020_DSAIL_SNU7\"\n",
    "\n",
    "\"\"\"\n",
    "To make it easier to run and modify the model, we'll copy the source code and \n",
    "model weights to the root of our git repo.\n",
    "\n",
    "First, we'll copy the following directories from `model_dir` to the root of our git repo:\n",
    "- `config` (includes confusion matrix weights, settings for data preprocessing etc.)\n",
    "- `output_training_directory` (checkpoints for model weights)\n",
    "\"\"\"\n",
    "\n",
    "result = shutil.copytree(team_dir / \"output_training_directory\", Path.cwd() / \"checkpoints\" / \"original\", dirs_exist_ok=True)\n",
    "print(result)\n",
    "\n",
    "# Don't want to overwrite if we make changes to config later on.\n",
    "try:\n",
    "    shutil.copytree(team_dir / \"config\", Path.cwd() / \"config\", dirs_exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"config directory already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = Path.cwd() / \"checkpoints\" / \"original\"\n",
    "config_dir = Path.cwd() / \"config\"\n",
    "# input_dir = Path.cwd() / \"data\" / \"challenge-2020\" / \"1.0.2\" / \"training\" / \"georgia\" / \"g1\"\n",
    "\n",
    "benchmark_dir = Path.cwd() / \"data\" / \"benchmark\"\n",
    "if not benchmark_dir.exists():\n",
    "    benchmark_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shaun/source/Thesis/PhysioNetChallenge2020/data/benchmark/norwegian-athlete-ecg already exists. Benchmark has already been run.\n"
     ]
    }
   ],
   "source": [
    "# Benchmark: norwegian-athlete-ecg\n",
    "input_dir = Path.cwd() / \"data\" / \"norwegian-athlete-ecg\" / \"1.0.0\"\n",
    "output_dir = benchmark_dir / \"norwegian-athlete-ecg\"\n",
    "\n",
    "if output_dir.exists():\n",
    "    print(f\"{output_dir} already exists. Benchmark has already been run.\")\n",
    "else:\n",
    "    # Run benchmark using modified PhysioNet Challenge 2020 driver.py\n",
    "    !python PhysioNet2020_driver.py {weights_dir} {config_dir} {input_dir} {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shaun/source/Thesis/PhysioNetChallenge2020/data/benchmark/georgia/g1 already exists. Benchmark has already been run.\n"
     ]
    }
   ],
   "source": [
    "# Benchmark: georgia, subset g1\n",
    "input_dir = Path.cwd() / \"data\" / \"challenge-2020\" / \"1.0.2\" / \"training\" / \"georgia\" / \"g1\"\n",
    "output_dir = benchmark_dir / \"georgia\" / \"g1\"\n",
    "\n",
    "if output_dir.exists():\n",
    "    print(f\"{output_dir} already exists. Benchmark has already been run.\")\n",
    "else:\n",
    "    # Run benchmark using modified PhysioNet Challenge 2020 driver.py\n",
    "    output_dir.mkdir(parents=True)\n",
    "    !python PhysioNet2020_driver.py {weights_dir} {config_dir} {input_dir} {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shaun/source/Thesis/PhysioNetChallenge2020/data/benchmark/cpsc_2018/g1 already exists. Benchmark has already been run.\n"
     ]
    }
   ],
   "source": [
    "# Benchmark: CPSC 2018 (not used for training by DSAIL_SNU)\n",
    "input_dir = Path.cwd() / \"data\" / \"challenge-2020\" / \"1.0.2\" / \"training\" / \"cpsc_2018\" / \"g1\"\n",
    "output_dir = benchmark_dir / \"cpsc_2018\" / \"g1\"\n",
    "\n",
    "if output_dir.exists():\n",
    "    print(f\"{output_dir} already exists. Benchmark has already been run.\")\n",
    "else:\n",
    "    # Run benchmark using modified PhysioNet Challenge 2020 driver.py\n",
    "    output_dir.mkdir(parents=True)\n",
    "    !python PhysioNet2020_driver.py {weights_dir} {config_dir} {input_dir} {output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only care about a subset of diagnosis labels which are easily misdiagnosed in athletes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sinus_labels = [426177001, 426783006, 427084000, 427393009]\n",
    "sinus_labels = [426177001, 426783006]       # Bradycardia or Normal\n",
    "rbbb_labels = [713427006, 713426002]        # Incomplete RBBB, Complete RBBB\n",
    "# won't do t-wave inversion, because no output for lead number provided.\n",
    "athlete_labels = sinus_labels + rbbb_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring (PhysioNet Challenge datasets)\n",
    "# input_dir = Path.cwd() / \"data\" / \"challenge-2020\" / \"1.0.2\" / \"training\" / \"georgia\" / \"g1\"\n",
    "# output_dir = benchmark_dir / \"georgia\" / \"g1\"\n",
    "input_dir = Path.cwd() / \"data\" / \"challenge-2020\" / \"1.0.2\" / \"training\" / \"cpsc_2018\" / \"g1\"\n",
    "output_dir = benchmark_dir / \"cpsc_2018\" / \"g1\"\n",
    "\n",
    "total_confusion = np.zeros((2,2), dtype=int)\n",
    "for entry in get_all_records(input_dir):\n",
    "    # Actual labels from PhysioNet Challenge dataset\n",
    "    record = wfdb.rdrecord(input_dir / entry)\n",
    "    comment_dx = record.comments[2].split(': ')[1]\n",
    "    actual_findings = list(map(int, comment_dx.split(',')))\n",
    "    actual_labels = codes_to_label_vector(actual_findings, athlete_labels)\n",
    "\n",
    "    # Predicted label from model\n",
    "    file = output_dir / (entry+'.csv')\n",
    "    predicted_findings = get_predicted_findings(file)\n",
    "    predicted_labels = codes_to_label_vector(predicted_findings, athlete_labels)\n",
    "\n",
    "    # Hack: If no sinus rhythm findings, assume normal sinus rhythm (426783006)\n",
    "    if sum(actual_labels) == 0:\n",
    "        actual_labels[1] = 1\n",
    "    if sum(predicted_labels) == 0:\n",
    "        predicted_labels[1] = 1\n",
    "    \n",
    "    # Calculate confusion matrix for entry, add to total\n",
    "    total_confusion += confusion_matrix(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classifier_metrics(tn, fp, fn, tp):\n",
    "    P = tp + fn\n",
    "    N = fp + tn\n",
    "    print(\"Population\")\n",
    "    print(\"----------\")\n",
    "    print(f\"Total population: {P+N}\")\n",
    "    print(f\"Positive: {P}\")\n",
    "    print(f\"Negative: {N}\\n\")\n",
    "\n",
    "    acc = (tp + tn) / (P+N)\n",
    "    ppv = tp / (tp + fp)\n",
    "    f1 = 2 * tp / (2*tp + fp + fn)\n",
    "    print(\"Performance\")\n",
    "    print(\"-----------\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Precision: {ppv}\")\n",
    "    print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2699,  298],\n",
       "       [ 289,  710]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population\n",
      "----------\n",
      "Total population: 3996\n",
      "Positive: 999\n",
      "Negative: 2997\n",
      "\n",
      "Performance\n",
      "-----------\n",
      "Accuracy: 0.8531031031031031\n",
      "Precision: 0.7043650793650794\n",
      "F1-Score: 0.7075236671649228\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = total_confusion.ravel()\n",
    "print_classifier_metrics(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring (norwegian-athlete-ecg)\n",
    "input_dir = Path.cwd() / \"data\" / \"norwegian-athlete-ecg\" / \"1.0.0\"\n",
    "output_dir = benchmark_dir / \"norwegian-athlete-ecg\"\n",
    "\n",
    "total_confusion = np.zeros((2,2), dtype=int)\n",
    "for entry in get_all_records(input_dir):\n",
    "    # Actual labels from dataset\n",
    "    record = wfdb.rdrecord(input_dir / entry)\n",
    "    comments_c = record.comments[1]\n",
    "    findings_c = norwegian.extract_findings(comments_c)\n",
    "\n",
    "    actual_findings = norwegian.classify_relevant_findings(findings_c)\n",
    "    actual_labels = codes_to_label_vector(actual_findings, athlete_labels)\n",
    "\n",
    "    # Predicted label from model\n",
    "    file = output_dir / (entry+'.csv')\n",
    "    predicted_findings = get_predicted_findings(file)\n",
    "    predicted_labels = codes_to_label_vector(predicted_findings, athlete_labels)\n",
    "\n",
    "    # Hack: If no sinus rhythm findings, assume normal sinus rhythm (426783006)\n",
    "    if sum(actual_labels) == 0:\n",
    "        actual_labels[1] = 1\n",
    "    if sum(predicted_labels) == 0:\n",
    "        predicted_labels[1] = 1\n",
    "    \n",
    "    # Calculate confusion matrix for entry, add to total\n",
    "    total_confusion += confusion_matrix(actual_labels, predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[63, 20],\n",
       "       [16, 13]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population\n",
      "----------\n",
      "Total population: 112\n",
      "Positive: 29\n",
      "Negative: 83\n",
      "\n",
      "Performance\n",
      "-----------\n",
      "Accuracy: 0.6785714285714286\n",
      "Precision: 0.3939393939393939\n",
      "F1-Score: 0.41935483870967744\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = total_confusion.ravel()\n",
    "print_classifier_metrics(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[713427006, 713426002]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete right bundle branch block\n",
      "Incomplete right bundle branch block\n"
     ]
    }
   ],
   "source": [
    "for finding in predicted_findings:\n",
    "    print(diagnosis_codes[finding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Collate diagnosis results into a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse engineering the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../media/DSAIL_model-architecture.jpg)\n",
    "\n",
    "***Figure: ResNet architecture***\n",
    "\n",
    "Ensemble of 10 neural networks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DSAIL = load_12ECG_model(weights_dir, config_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dsail.config.DataConfig'>\n",
      "<class 'dsail.config.PreprocessConfig'>\n",
      "<class 'dsail.config.RunConfig'>\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for thing in model_DSAIL:\n",
    "    print(type(thing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n",
      "<class 'dsail.model.model.ECG_model'>\n"
     ]
    }
   ],
   "source": [
    "for net in model_DSAIL[3]:\n",
    "    print(type(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.bn1.running_mean\n",
      "layer1.0.bn1.running_var\n",
      "layer1.0.bn1.num_batches_tracked\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.0.bn2.running_mean\n",
      "layer1.0.bn2.running_var\n",
      "layer1.0.bn2.num_batches_tracked\n",
      "layer1.0.conv1.1.weight\n",
      "layer1.0.conv2.1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.bn1.running_mean\n",
      "layer1.1.bn1.running_var\n",
      "layer1.1.bn1.num_batches_tracked\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer1.1.bn2.running_mean\n",
      "layer1.1.bn2.running_var\n",
      "layer1.1.bn2.num_batches_tracked\n",
      "layer1.1.conv1.1.weight\n",
      "layer1.1.conv2.1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.bn1.running_mean\n",
      "layer2.0.bn1.running_var\n",
      "layer2.0.bn1.num_batches_tracked\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.bn2.running_mean\n",
      "layer2.0.bn2.running_var\n",
      "layer2.0.bn2.num_batches_tracked\n",
      "layer2.0.conv1.1.weight\n",
      "layer2.0.conv2.1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.bn1.running_mean\n",
      "layer2.1.bn1.running_var\n",
      "layer2.1.bn1.num_batches_tracked\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer2.1.bn2.running_mean\n",
      "layer2.1.bn2.running_var\n",
      "layer2.1.bn2.num_batches_tracked\n",
      "layer2.1.conv1.1.weight\n",
      "layer2.1.conv2.1.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.bn1.running_mean\n",
      "layer3.0.bn1.running_var\n",
      "layer3.0.bn1.num_batches_tracked\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.bn2.running_mean\n",
      "layer3.0.bn2.running_var\n",
      "layer3.0.bn2.num_batches_tracked\n",
      "layer3.0.conv1.1.weight\n",
      "layer3.0.conv2.1.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.bn1.running_mean\n",
      "layer3.1.bn1.running_var\n",
      "layer3.1.bn1.num_batches_tracked\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer3.1.bn2.running_mean\n",
      "layer3.1.bn2.running_var\n",
      "layer3.1.bn2.num_batches_tracked\n",
      "layer3.1.conv1.1.weight\n",
      "layer3.1.conv2.1.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.bn1.running_mean\n",
      "layer4.0.bn1.running_var\n",
      "layer4.0.bn1.num_batches_tracked\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.bn2.running_mean\n",
      "layer4.0.bn2.running_var\n",
      "layer4.0.bn2.num_batches_tracked\n",
      "layer4.0.conv1.1.weight\n",
      "layer4.0.conv2.1.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.bn1.running_mean\n",
      "layer4.1.bn1.running_var\n",
      "layer4.1.bn1.num_batches_tracked\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "layer4.1.bn2.running_mean\n",
      "layer4.1.bn2.running_var\n",
      "layer4.1.bn2.num_batches_tracked\n",
      "layer4.1.conv1.1.weight\n",
      "layer4.1.conv2.1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "bn1.running_mean\n",
      "bn1.running_var\n",
      "bn1.num_batches_tracked\n",
      "linear.weight\n",
      "linear.bias\n"
     ]
    }
   ],
   "source": [
    "for state in net.state_dict():\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG_model(\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(12, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "        (1): Conv1d(32, 64, kernel_size=(11,), stride=(4,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "        (1): Conv1d(64, 128, kernel_size=(11,), stride=(4,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "        (1): Conv1d(128, 256, kernel_size=(11,), stride=(4,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNet_Basic_Block(\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (conv1): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "        (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (linear): Linear(in_features=256, out_features=24, bias=True)\n",
      ")\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(12, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(12, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (1): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      ")\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "***\n",
      "BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential()\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "***\n",
      "BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(32, 32, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential()\n",
      "***\n",
      "Sequential(\n",
      "  (0): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "      (1): Conv1d(32, 64, kernel_size=(11,), stride=(4,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      ")\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "    (1): Conv1d(32, 64, kernel_size=(11,), stride=(4,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential(\n",
      "    (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "***\n",
      "BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "  (1): Conv1d(32, 64, kernel_size=(11,), stride=(4,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(3, 4), value=0)\n",
      "***\n",
      "Conv1d(32, 64, kernel_size=(11,), stride=(4,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "***\n",
      "MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "***\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(64, 64, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential()\n",
      "***\n",
      "Sequential(\n",
      "  (0): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "      (1): Conv1d(64, 128, kernel_size=(11,), stride=(4,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      ")\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "    (1): Conv1d(64, 128, kernel_size=(11,), stride=(4,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential(\n",
      "    (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "***\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "  (1): Conv1d(64, 128, kernel_size=(11,), stride=(4,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(3, 4), value=0)\n",
      "***\n",
      "Conv1d(64, 128, kernel_size=(11,), stride=(4,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "***\n",
      "MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "***\n",
      "BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(128, 128, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential()\n",
      "***\n",
      "Sequential(\n",
      "  (0): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "      (1): Conv1d(128, 256, kernel_size=(11,), stride=(4,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): ResNet_Basic_Block(\n",
      "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (conv1): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "      (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      ")\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "    (1): Conv1d(128, 256, kernel_size=(11,), stride=(4,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential(\n",
      "    (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "***\n",
      "BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(3, 4), value=0)\n",
      "  (1): Conv1d(128, 256, kernel_size=(11,), stride=(4,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(3, 4), value=0)\n",
      "***\n",
      "Conv1d(128, 256, kernel_size=(11,), stride=(4,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "***\n",
      "MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "***\n",
      "ResNet_Basic_Block(\n",
      "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (conv1): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "    (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "***\n",
      "BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential(\n",
      "  (0): ConstantPad1d(padding=(5, 5), value=0)\n",
      "  (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      ")\n",
      "***\n",
      "ConstantPad1d(padding=(5, 5), value=0)\n",
      "***\n",
      "Conv1d(256, 256, kernel_size=(11,), stride=(1,), bias=False)\n",
      "***\n",
      "Sequential()\n",
      "***\n",
      "BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "***\n",
      "ReLU()\n",
      "***\n",
      "Dropout(p=0.3, inplace=False)\n",
      "***\n",
      "AdaptiveMaxPool1d(output_size=1)\n",
      "***\n",
      "Linear(in_features=256, out_features=24, bias=True)\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "for module in net.modules():\n",
    "    print(module)\n",
    "    print(\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ECG_model                                --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─ConstantPad1d: 2-1                --\n",
       "│    └─Conv1d: 2-2                       4,224\n",
       "├─Sequential: 1-2                        --\n",
       "│    └─ResNet_Basic_Block: 2-3           --\n",
       "│    │    └─BatchNorm1d: 3-1             64\n",
       "│    │    └─BatchNorm1d: 3-2             64\n",
       "│    │    └─ReLU: 3-3                    --\n",
       "│    │    └─Dropout: 3-4                 --\n",
       "│    │    └─Sequential: 3-5              11,264\n",
       "│    │    └─Sequential: 3-6              11,264\n",
       "│    │    └─Sequential: 3-7              --\n",
       "│    └─ResNet_Basic_Block: 2-4           --\n",
       "│    │    └─BatchNorm1d: 3-8             64\n",
       "│    │    └─BatchNorm1d: 3-9             64\n",
       "│    │    └─ReLU: 3-10                   --\n",
       "│    │    └─Dropout: 3-11                --\n",
       "│    │    └─Sequential: 3-12             11,264\n",
       "│    │    └─Sequential: 3-13             11,264\n",
       "│    │    └─Sequential: 3-14             --\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─ResNet_Basic_Block: 2-5           --\n",
       "│    │    └─BatchNorm1d: 3-15            64\n",
       "│    │    └─BatchNorm1d: 3-16            128\n",
       "│    │    └─ReLU: 3-17                   --\n",
       "│    │    └─Dropout: 3-18                --\n",
       "│    │    └─Sequential: 3-19             22,528\n",
       "│    │    └─Sequential: 3-20             45,056\n",
       "│    │    └─Sequential: 3-21             --\n",
       "│    └─ResNet_Basic_Block: 2-6           --\n",
       "│    │    └─BatchNorm1d: 3-22            128\n",
       "│    │    └─BatchNorm1d: 3-23            128\n",
       "│    │    └─ReLU: 3-24                   --\n",
       "│    │    └─Dropout: 3-25                --\n",
       "│    │    └─Sequential: 3-26             45,056\n",
       "│    │    └─Sequential: 3-27             45,056\n",
       "│    │    └─Sequential: 3-28             --\n",
       "├─Sequential: 1-4                        --\n",
       "│    └─ResNet_Basic_Block: 2-7           --\n",
       "│    │    └─BatchNorm1d: 3-29            128\n",
       "│    │    └─BatchNorm1d: 3-30            256\n",
       "│    │    └─ReLU: 3-31                   --\n",
       "│    │    └─Dropout: 3-32                --\n",
       "│    │    └─Sequential: 3-33             90,112\n",
       "│    │    └─Sequential: 3-34             180,224\n",
       "│    │    └─Sequential: 3-35             --\n",
       "│    └─ResNet_Basic_Block: 2-8           --\n",
       "│    │    └─BatchNorm1d: 3-36            256\n",
       "│    │    └─BatchNorm1d: 3-37            256\n",
       "│    │    └─ReLU: 3-38                   --\n",
       "│    │    └─Dropout: 3-39                --\n",
       "│    │    └─Sequential: 3-40             180,224\n",
       "│    │    └─Sequential: 3-41             180,224\n",
       "│    │    └─Sequential: 3-42             --\n",
       "├─Sequential: 1-5                        --\n",
       "│    └─ResNet_Basic_Block: 2-9           --\n",
       "│    │    └─BatchNorm1d: 3-43            256\n",
       "│    │    └─BatchNorm1d: 3-44            512\n",
       "│    │    └─ReLU: 3-45                   --\n",
       "│    │    └─Dropout: 3-46                --\n",
       "│    │    └─Sequential: 3-47             360,448\n",
       "│    │    └─Sequential: 3-48             720,896\n",
       "│    │    └─Sequential: 3-49             --\n",
       "│    └─ResNet_Basic_Block: 2-10          --\n",
       "│    │    └─BatchNorm1d: 3-50            512\n",
       "│    │    └─BatchNorm1d: 3-51            512\n",
       "│    │    └─ReLU: 3-52                   --\n",
       "│    │    └─Dropout: 3-53                --\n",
       "│    │    └─Sequential: 3-54             720,896\n",
       "│    │    └─Sequential: 3-55             720,896\n",
       "│    │    └─Sequential: 3-56             --\n",
       "├─BatchNorm1d: 1-6                       512\n",
       "├─ReLU: 1-7                              --\n",
       "├─Dropout: 1-8                           --\n",
       "├─AdaptiveMaxPool1d: 1-9                 --\n",
       "├─Linear: 1-10                           6,168\n",
       "=================================================================\n",
       "Total params: 3,370,968\n",
       "Trainable params: 3,370,968\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying model weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
