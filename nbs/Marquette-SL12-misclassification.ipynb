{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misclassification of athlete ECG by GE Marquette SL12 algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Click to see packages imported\"\n",
    "import os\n",
    "import configparser\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, List\n",
    "from enum import Enum\n",
    "\n",
    "import wfdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|include: false\n",
    "# If the current working directory is the nbs/ folder, change to the project \n",
    "# root directory instead.\n",
    "\n",
    "if Path.cwd().stem == \"nbs\":\n",
    "    os.chdir(Path.cwd().parent)\n",
    "print(f\"The current working directory is {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|include: false\n",
    "# Import configuration settings, like location of data directory.\n",
    "config = configparser.ConfigParser()\n",
    "if not Path(\"config.ini\").exists():\n",
    "    print(\"WARNING: Please generate a config.ini file by running scripts/get_datasets.py\")\n",
    "else:\n",
    "    config.read(\"config.ini\")\n",
    "    data_dir = Path((config[\"datasets\"][\"path\"])).expanduser()\n",
    "    print(f\"Datasets are located at {data_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The norwegian-athlete-ecg dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Norwegian Endurance Athlete ECG Database](https://physionet.org/content/norwegian-athlete-ecg/1.0.0/) (norwegian-athlete-ecg) contains 12-lead ECG recordings from 28 elite athletes from various sports in Norway. All recordings are 10 seconds resting ECGs recorded with a General Electric (GE) MAC VUE 360 electrocardiograph. All ECGs are interpreted with both the GE Marquette SL12 algorithm (version 23 (v243)) and one cardiologist with training in interpretation of athlete's ECG. The data was collected at the University of Oslo in February and March 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_ecg_dir = data_dir / \"norwegian-athlete-ecg\" / \"1.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: \"12-lead ECG recording from subject ath_001\"\n",
    "record = wfdb.rdrecord(athlete_ecg_dir / \"ath_001\")\n",
    "wfdb.plot_wfdb(record=record, title='ath_001 from Norwegian Athlete ECG database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: \"Machine (SL12) and Cardiologist (C) interpretation of ath_001 ECG recording\"\n",
    "record = wfdb.rdheader(athlete_ecg_dir / \"ath_001\")\n",
    "record.__dict__[\"comments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Put ECG finding reports into a pandas dataframe\n",
    "class AthleteReport():\n",
    "    athlete_id: str\n",
    "    cardiologist: str\n",
    "    machine: str\n",
    "\n",
    "reports_list = []\n",
    "for i in range(1, 29):\n",
    "    athlete_id = f\"ath_00{i}\" if i < 10 else f\"ath_0{i}\"\n",
    "    record = wfdb.rdheader(athlete_ecg_dir / athlete_id)\n",
    "    comments = record.__dict__[\"comments\"]\n",
    "    report: AthleteReport = {\n",
    "        \"athlete_id\": athlete_id,\n",
    "        \"cardiologist\": comments[1],\n",
    "        \"machine\": comments[0],\n",
    "    }\n",
    "    reports_list.append(report)\n",
    "athlete_ecg_df = pd.DataFrame(reports_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_ecg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings from ECG reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the norwegian-athlete-ecg dataset, findings in ECG reports are delimited by \n",
    "a comma (`,`). However, some machine findings also make use of a comma to make \n",
    "a follow-up comment on a finding. This is not done in any of the human \n",
    "cardiologist reports in the dataset.\n",
    "\n",
    "***Table: Examples of findings with follow-up comment***\n",
    "\n",
    "| Finding with follow-up comment | Record |\n",
    "|-|-|\n",
    "| `Minimal voltage criteria for LVH, may be normal variant` | `ath_024` |\n",
    "| `ST elevation, probably due to early repolarization` | `ath_024` |\n",
    "| `ST elevation, consider early repolarization, pericarditis, or injury` | `ath_27` |\n",
    "\n",
    "Follow-up comments from SL12 all seem to start with a lower-case letter, so \n",
    "they can be detected this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Click to see function for extracting a list of findings from a single line report\n",
    "\n",
    "def extract_findings(report: str, follow_on: bool=True) -> List[str]:\n",
    "    \"\"\"Extract a list of all findings in a single line cardiologist report\n",
    "    \"\"\"\n",
    "    comments = report.split(': ', maxsplit=1)[1].split(', ')\n",
    "\n",
    "    # Cleanup (e.g. remove leading/trailing whitespace)\n",
    "    comments[:] = list(map(str.strip, comments))\n",
    "\n",
    "    if not follow_on:\n",
    "        return comments     # i.e. assume every comment is a new finding\n",
    "\n",
    "    # Combine follow-on comments with parent comment to produce full finding \n",
    "    # for SL12 machine comments.\n",
    "    #\n",
    "    # e.g. ST elevation, consider early repolarization, pericarditis, or injury\n",
    "    findings = []\n",
    "    for i, comment in enumerate(comments):\n",
    "        if comment[0].isupper() or comment[0] == '*':\n",
    "            findings.append(comment)\n",
    "        else:\n",
    "            findings[-1] = ''.join([findings[-1], \", \", comment])\n",
    "    return findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of `extract_findings()`\n",
    "report = athlete_ecg_df.loc[23].machine\n",
    "extract_findings(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: Find every unique finding in dataset\n",
    "unique_findings_sl12 = []\n",
    "unique_findings_c = []\n",
    "for i in range(1, 29):\n",
    "    athlete_id = f\"ath_00{i}\" if i < 10 else f\"ath_0{i}\"\n",
    "    record = wfdb.rdheader(athlete_ecg_dir / athlete_id)\n",
    "    comments = record.__dict__[\"comments\"]\n",
    "\n",
    "    # Machine algorithm findings\n",
    "    findings_sl12 = extract_findings(comments[0])\n",
    "    for finding in findings_sl12:\n",
    "        if finding not in unique_findings_sl12:\n",
    "            unique_findings_sl12.append(finding)\n",
    "    \n",
    "    # Cardiologist findings\n",
    "    findings_c = extract_findings(comments[1], follow_on=False)\n",
    "    for finding in findings_c:\n",
    "        if finding not in unique_findings_c:\n",
    "            unique_findings_c.append(finding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_findings_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_findings_sl12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disagreement between machine and cardiologist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying findings by the type of abnormality\n",
    "\n",
    "class AbnormalityClass(Enum):\n",
    "    # overall = \"Overall ECG recording\"   # Normal/Abnormal/Borderline etc.\n",
    "    rhythm = \"Rhythm\"                   # e.g. sinus rhythm\n",
    "    conduction = \"Conduction\"           # e.g. bundle branch block, AV block\n",
    "    ischemia = \"Ischemia\"               # e.g. ST-segment, T-wave inversion\n",
    "    structural = \"Structural\"           # e.g. chamber enlargement, hypertrophy\n",
    "    measurement = \"Measurement\"         # e.g. axis deviation, wide QRS, PR interval\n",
    "    equipment = \"Equipment\"             # e.g. Misplaced electrodes\n",
    "    other = \"Other\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final finding in each report is an \"overall\" classification for the \n",
    "# entire ECG recording.\n",
    "\n",
    "# We can use the difference between machine and cardiologist\n",
    "\n",
    "class OverallFinding(Enum):\n",
    "    Unknown = -5\n",
    "    Normal = 0\n",
    "    Borderline = 1\n",
    "    Abnormal = 2\n",
    "\n",
    "def classifyOverallFinding(findings: List[str]) -> OverallFinding:\n",
    "    \"\"\"Classifies the overall finding for an ECG recording.\n",
    "\n",
    "    Assumes that the final finding in `findings` list comments on overall \n",
    "    finding.\n",
    "    \"\"\"\n",
    "    overall = findings[-1].lower()\n",
    "    if overall.find(\"abnormal\") != -1:\n",
    "        return OverallFinding.Abnormal\n",
    "    elif overall.find(\"borderline\") != -1:\n",
    "        return OverallFinding.Borderline\n",
    "    elif overall.find(\"normal\") != -1:\n",
    "        return OverallFinding.Normal\n",
    "    else:\n",
    "        return OverallFinding.Unknown\n",
    "\n",
    "# Example usage of `classifyOverallFindings`:\n",
    "# Quantify the \"overall disagreement\" between cardiologist and SL12 algorithm.\n",
    "for i in range(1, 29):\n",
    "    athlete_id = f\"ath_00{i}\" if i < 10 else f\"ath_0{i}\"\n",
    "\n",
    "    record = wfdb.rdheader(athlete_ecg_dir / athlete_id)\n",
    "    comments = record.__dict__[\"comments\"]\n",
    "\n",
    "    findings_sl12 = extract_findings(comments[0])\n",
    "    findings_c = extract_findings(comments[1])\n",
    "\n",
    "    overall_sl12 = classifyOverallFinding(findings_sl12)\n",
    "    overall_c = classifyOverallFinding(findings_c)\n",
    "\n",
    "    print(f\"{athlete_id} disagreement = {overall_sl12.value - overall_c.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Disagreement between cardiologist and machine for individual abnormality \n",
    "classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
