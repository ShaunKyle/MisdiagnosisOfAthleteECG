{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pro-Football 12-lead Resting Electrocardiogram Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data collected**\n",
    "\n",
    "The data were gathered from La Liga, Spain, from professional football players. \n",
    "\n",
    "Resting in supine position, each participant ºs 12-lead electrocardiogram (ECG) was captured with General Electrics (GE) USB-CAM 14 for a duration of 10 s at 500 Hz using the GE CardioSoft software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Click to see packages imported\"\n",
    "import os\n",
    "import configparser\n",
    "import random\n",
    "import shutil\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import wfdb\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is c:\\Users\\Shaun\\source\\Thesis\\MisdiagnosisOfAthleteECG\n"
     ]
    }
   ],
   "source": [
    "#|include: false\n",
    "# If the current working directory is the nbs/ folder, change to the project \n",
    "# root directory instead.\n",
    "if Path.cwd().stem == \"nbs\":\n",
    "    os.chdir(Path.cwd().parent)\n",
    "print(f\"The current working directory is {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets are located at C:\\Users\\Shaun\\source\\Thesis\\MisdiagnosisOfAthleteECG\\data\n"
     ]
    }
   ],
   "source": [
    "#|include: false\n",
    "# Import configuration settings, like location of data directory.\n",
    "config = configparser.ConfigParser()\n",
    "if not Path(\"config.ini\").exists():\n",
    "    print(\"WARNING: Please generate a config.ini file by running scripts/get_datasets.py\")\n",
    "else:\n",
    "    config.read(\"config.ini\")\n",
    "    data_dir = Path((config[\"datasets\"][\"path\"])).expanduser()\n",
    "    print(f\"Datasets are located at {data_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from GE Muse XML to WFDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/PierreElias/IntroECG/tree/master/1-Waveform%20Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf12red_xml_dir = data_dir / \"pf12red\" / \"5 163XML\"\n",
    "pf12red_extracted_dir  = data_dir / \"pf12red\" / \"extracted\"\n",
    "pf12red_labels_file = data_dir / \"pf12red\" / \"labels.csv\"\n",
    "\n",
    "if not pf12red_extracted_dir.exists():\n",
    "    pf12red_extracted_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AthleteID</th>\n",
       "      <th>SR</th>\n",
       "      <th>SB</th>\n",
       "      <th>iRBBB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AthleteID   SR   SB iRBBB\n",
       "0          1  NaN    X     X\n",
       "1          2    X  NaN   NaN\n",
       "2          3  NaN    X     X\n",
       "3          4  NaN    X   NaN\n",
       "4          5  NaN    X   NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(pf12red_labels_file)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AthleteID</th>\n",
       "      <th>SR</th>\n",
       "      <th>SB</th>\n",
       "      <th>iRBBB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AthleteID   SR SB iRBBB\n",
       "9         10  NaN  X   NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df[labels_df.AthleteID == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels_df[labels_df.AthleteID == 10].SB == \"X\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't write 10_1819Pst\n",
      "Couldn't write 11_1819Pst\n",
      "Couldn't write 11_1920Pre\n",
      "Couldn't write 12_1819Pst\n",
      "Couldn't write 12_1920Pre\n",
      "Couldn't write 12_1920Pst\n",
      "Couldn't write 12_2021Pre\n",
      "Couldn't write 12_2122Pre\n",
      "Couldn't write 13_1819Pst\n",
      "Couldn't write 13_1920Pre\n",
      "Couldn't write 13_1920Pst\n",
      "Couldn't write 13_2021Pre\n",
      "Couldn't write 13_2122Pre\n",
      "Couldn't write 14_1819Pst\n",
      "Couldn't write 14_1920Pre\n",
      "Couldn't write 14_1920Pst\n",
      "Couldn't write 15_1920Pre\n",
      "Couldn't write 15_1920Pst\n",
      "Couldn't write 15_2021Pre\n",
      "Couldn't write 15_2122Pre\n",
      "Couldn't write 16_1920Pre\n",
      "Couldn't write 16_2021Pre\n",
      "Couldn't write 17_1819Pst\n",
      "Couldn't write 18_1819Pst\n",
      "Couldn't write 18_1920Pre\n",
      "Couldn't write 18_1920Pst\n",
      "Couldn't write 18_2021Pre\n",
      "Couldn't write 18_2122Pre\n",
      "Couldn't write 19_1819Pst\n",
      "Couldn't write 19_1920Pre\n",
      "Couldn't write 19_1920Pst\n",
      "Couldn't write 19_2021Pre\n",
      "Couldn't write 19_2122Pre\n",
      "Couldn't write 1_1819Pst\n",
      "Couldn't write 20_1819Pst\n",
      "Couldn't write 20_1920Pre\n",
      "Couldn't write 21_1819Pst\n",
      "Couldn't write 21_1920Pre\n",
      "Couldn't write 21_1920Pst\n",
      "Couldn't write 22_1819Pst\n",
      "Couldn't write 22_1920Pre\n",
      "Couldn't write 22_1920Pst\n",
      "Couldn't write 22_2021Pre\n",
      "Couldn't write 22_2122Pre\n",
      "Couldn't write 23_1819Pst\n",
      "Couldn't write 23_1920Pre\n",
      "Couldn't write 23_1920Pst\n",
      "Couldn't write 23_2021Pre\n",
      "Couldn't write 23_2122Pre\n",
      "Couldn't write 24_1819Pst\n",
      "Couldn't write 24_1920Pre\n",
      "Couldn't write 25_1819Pst\n",
      "Couldn't write 25_1920Pre\n",
      "Couldn't write 25_1920Pst\n",
      "Couldn't write 25_2021Pre\n",
      "Couldn't write 25_2122Pre\n",
      "Couldn't write 26_1920Pre\n",
      "Couldn't write 27_1920Pre\n",
      "Couldn't write 27_1920Pst\n",
      "Couldn't write 27_2021Pre\n",
      "Couldn't write 28_1920Pre\n",
      "Couldn't write 28_1920Pst\n",
      "Couldn't write 28_2021Pre\n",
      "Couldn't write 28_2122Pre\n",
      "Couldn't write 29_1920Pre\n",
      "Couldn't write 29_1920Pst\n",
      "Couldn't write 29_2021Pre\n",
      "Couldn't write 2_1819Pst\n",
      "Couldn't write 2_2021Pre\n",
      "Couldn't write 2_2122Pre\n",
      "Couldn't write 30_1920Pre\n",
      "Couldn't write 30_1920Pst\n",
      "Couldn't write 30_2021Pre\n",
      "Couldn't write 30_2122Pre\n",
      "Couldn't write 31_1920Pre\n",
      "Couldn't write 32_1920Pre\n",
      "Couldn't write 32_1920Pst\n",
      "Couldn't write 32_2021Pre\n",
      "Couldn't write 32_2122Pre\n",
      "Couldn't write 33_1920Pre\n",
      "Couldn't write 34_1920Pre\n",
      "Couldn't write 34_1920Pst\n",
      "Couldn't write 34_2021Pre\n",
      "Couldn't write 34_2122Pre\n",
      "Couldn't write 35_1920Pre\n",
      "Couldn't write 35_1920Pst\n",
      "Couldn't write 35_2021Pre\n",
      "Couldn't parse data\\pf12red\\5 163XML\\35_2122Pre.XML\n",
      "Couldn't write 35_2122Pre\n",
      "Couldn't write 36_1920Pre\n",
      "Couldn't write 36_1920Pst\n",
      "Couldn't write 36_2021Pre\n",
      "Couldn't write 37_1920Pre\n",
      "Couldn't write 37_1920Pst\n",
      "Couldn't write 37_2021Pre\n",
      "Couldn't write 37_2122Pre\n",
      "Couldn't write 38_1920Pre\n",
      "Couldn't write 38_1920Pst\n",
      "Couldn't write 38_2021Pre\n",
      "Couldn't write 38_2122Pre\n",
      "Couldn't write 39_1920Pst\n",
      "Couldn't write 39_2021Pre\n",
      "Couldn't write 39_2122Pre\n",
      "Couldn't write 3_1819Pst\n",
      "Couldn't write 3_1920Pre\n",
      "Couldn't write 40_1920Pst\n",
      "Couldn't write 41_1920Pst\n",
      "Couldn't write 41_2021Pre\n",
      "Couldn't write 42_1920Pre\n",
      "Couldn't write 42_1920Pst\n",
      "Couldn't write 42_2021Pre\n",
      "Couldn't write 42_2122Pre\n",
      "Couldn't write 43_1920Pst\n",
      "Couldn't write 43_2021Pre\n",
      "Couldn't write 44_1920Pre\n",
      "Couldn't write 44_1920Pst\n",
      "Couldn't write 44_2021Pre\n",
      "Couldn't write 44_2122Pre\n",
      "Couldn't write 45_1920Pre\n",
      "Couldn't write 45_1920Pst\n",
      "Couldn't write 45_2021Pre\n",
      "Couldn't write 45_2122Pre\n",
      "Couldn't write 46_2021Pre\n",
      "Couldn't write 47_2021Pre\n",
      "Couldn't write 47_2122Pre\n",
      "Couldn't write 48_1920Pre\n",
      "Couldn't write 48_1920Pst\n",
      "Couldn't write 48_2021Pre\n",
      "Couldn't write 48_2122Pre\n",
      "Couldn't write 49_2021Pre\n",
      "Couldn't write 4_1819Pst\n",
      "Couldn't write 4_1920Pre\n",
      "Couldn't write 4_1920Pst\n",
      "Couldn't write 4_2021Pre\n",
      "Couldn't write 50_1920Pre\n",
      "Couldn't write 50_1920Pst\n",
      "Couldn't write 50_2122Pre\n",
      "Couldn't write 51_1920Pre\n",
      "Couldn't write 51_1920Pst\n",
      "Couldn't write 51_2021Pre\n",
      "Couldn't write 51_2122Pre\n",
      "Couldn't write 52_2021Pre\n",
      "Couldn't write 52_2122Pre\n",
      "Couldn't write 53_2021Pre\n",
      "Couldn't write 53_2122Pre\n",
      "Couldn't write 54_1920Pre\n",
      "Couldn't write 5_1819Pst\n",
      "Couldn't write 5_1920Pre\n",
      "Couldn't write 5_1920Pst\n",
      "Couldn't write 6_1819Pst\n",
      "Couldn't write 6_1920Pre\n",
      "Couldn't write 6_1920Pst\n",
      "Couldn't write 6_2021Pre\n",
      "Couldn't write 7_1819Pst\n",
      "Couldn't write 7_1920Pre\n",
      "Couldn't write 7_2021Pre\n",
      "Couldn't write 7_2122Pre\n",
      "Couldn't write 8_1819Pst\n",
      "Couldn't write 8_1920Pre\n",
      "Couldn't write 8_1920Pst\n",
      "Couldn't write 8_2021Pre\n",
      "Couldn't write 9_1819Pst\n",
      "Couldn't write 9_1920Pre\n",
      "Couldn't write 9_2021Pre\n"
     ]
    }
   ],
   "source": [
    "for file in pf12red_xml_dir.iterdir():\n",
    "    # Only process XML files\n",
    "    if file.suffix != '.XML':\n",
    "        print(f\"How did {file} get there?\")\n",
    "        continue\n",
    "    \n",
    "    # Attempt to parse XML file using xmltodict package\n",
    "    with open(file, 'rb') as f:\n",
    "        xml_str = f.read().decode('utf8')\n",
    "    try:\n",
    "        xml_dict = xmltodict.parse(xml_str)\n",
    "    except:\n",
    "        print(f\"Couldn't parse {file}\")\n",
    "    \n",
    "    # Extract patient info\n",
    "    age = xml_dict['CardiologyXML']['PatientInfo']['Age']['#text']\n",
    "    gender = xml_dict['CardiologyXML']['PatientInfo']['Gender']\n",
    "\n",
    "    # Extract diagnosis info (save as SNOMED-CT codes)\n",
    "    athlete_id = int(file.stem.split('_')[0])\n",
    "    labels = labels_df[labels_df.AthleteID == athlete_id]\n",
    "    dx_comment = \"Dx: \"\n",
    "    # TODO: What does SR label mean?\n",
    "    # if labels.SR == 'X':\n",
    "    #     dx_comment += \"426783006\"   # Normal sinus rhythm\n",
    "    #     dx_comment += \"427393009\"   # Sinus arrhythmia\n",
    "    if (labels.SB == 'X').item():\n",
    "        dx_comment += \"426177001,\"\n",
    "    if (labels.iRBBB == 'X').item():\n",
    "        dx_comment += \"713426002,\"\n",
    "\n",
    "    # Extract lead waveforms (version 1)\n",
    "    lead_samples = []\n",
    "    for i in range(12):\n",
    "        # sample_str = xml_dict['CardiologyXML']['RestingECGMeasurements']['MedianSamples']['WaveformData'][i]['#text']\n",
    "        sample_str = xml_dict['CardiologyXML']['StripData']['WaveformData'][0]['#text']\n",
    "        sample_list = list(map(int, sample_str.split(',')))\n",
    "        lead_samples.append(np.array(sample_list, dtype=int))\n",
    "    p_signal = np.stack(lead_samples) * 0.005\n",
    "    p_signal= p_signal.transpose()\n",
    "    \n",
    "    # Write new WFDB record\n",
    "    # print(f\"Writing {file.stem}\")\n",
    "    try:\n",
    "        wfdb.wrsamp(\n",
    "            file.stem, \n",
    "            fs=500, \n",
    "            units=['mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV'],\n",
    "            sig_name=['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'],\n",
    "            p_signal=p_signal,\n",
    "            comments=[f\"age: {age}\", f\"gender: {gender}\", {dx_comment}],\n",
    "            write_dir=pf12red_extracted_dir,\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Couldn't write {file.stem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What should the p_signal look like?\n",
    "norwegian_dataset_dir = data_dir / \"norwegian-athlete-ecg\" / \"1.0.0\"\n",
    "record = wfdb.rdrecord(norwegian_dataset_dir / \"ath_001\")\n",
    "record.p_signal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting waveform from PDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
