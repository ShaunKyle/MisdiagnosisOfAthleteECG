{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pro-Football 12-lead Resting Electrocardiogram Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data collected**\n",
    "\n",
    "The data were gathered from La Liga, Spain, from professional football players. \n",
    "\n",
    "Resting in supine position, each participant ºs 12-lead electrocardiogram (ECG) was captured with General Electrics (GE) USB-CAM 14 for a duration of 10 s at 500 Hz using the GE CardioSoft software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Click to see packages imported\"\n",
    "import os\n",
    "import configparser\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import wfdb\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is c:\\Users\\Shaun\\source\\Thesis\\MisdiagnosisOfAthleteECG\n"
     ]
    }
   ],
   "source": [
    "#|include: false\n",
    "# If the current working directory is the nbs/ folder, change to the project \n",
    "# root directory instead.\n",
    "if Path.cwd().stem == \"nbs\":\n",
    "    os.chdir(Path.cwd().parent)\n",
    "print(f\"The current working directory is {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets are located at C:\\Users\\Shaun\\source\\Thesis\\MisdiagnosisOfAthleteECG\\data\n"
     ]
    }
   ],
   "source": [
    "#|include: false\n",
    "# Import configuration settings, like location of data directory.\n",
    "config = configparser.ConfigParser()\n",
    "if not Path(\"config.ini\").exists():\n",
    "    print(\"WARNING: Please generate a config.ini file by running scripts/get_datasets.py\")\n",
    "else:\n",
    "    config.read(\"config.ini\")\n",
    "    data_dir = Path((config[\"datasets\"][\"path\"])).expanduser()\n",
    "    print(f\"Datasets are located at {data_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from GE Muse XML to WFDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/PierreElias/IntroECG/tree/master/1-Waveform%20Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf12red_xml_dir = data_dir / \"pf12red\" / \"5 163XML\"\n",
    "pf12red_extracted_dir  = data_dir / \"pf12red\" / \"extracted\"\n",
    "pf12red_labels_file = data_dir / \"pf12red\" / \"labels.csv\"\n",
    "\n",
    "# Start with empty directory\n",
    "if pf12red_extracted_dir.exists():\n",
    "    shutil.rmtree(pf12red_extracted_dir)\n",
    "pf12red_extracted_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AthleteID</th>\n",
       "      <th>SR</th>\n",
       "      <th>SB</th>\n",
       "      <th>iRBBB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AthleteID   SR   SB iRBBB\n",
       "0          1  NaN    X     X\n",
       "1          2    X  NaN   NaN\n",
       "2          3  NaN    X     X\n",
       "3          4  NaN    X   NaN\n",
       "4          5  NaN    X   NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(pf12red_labels_file)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AthleteID</th>\n",
       "      <th>SR</th>\n",
       "      <th>SB</th>\n",
       "      <th>iRBBB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AthleteID   SR SB iRBBB\n",
       "9         10  NaN  X   NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df[labels_df.AthleteID == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels_df[labels_df.AthleteID == 10].SB == \"X\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't write 11_1920Pre\n",
      "Removed garbage .hea file\n",
      "Couldn't write 13_1920Pst\n",
      "Removed garbage .hea file\n",
      "Couldn't write 14_1920Pst\n",
      "Removed garbage .hea file\n",
      "Couldn't write 19_1920Pst\n",
      "Removed garbage .hea file\n",
      "Couldn't write 1_1819Pst\n",
      "Removed garbage .hea file\n",
      "Couldn't write 20_1819Pst\n",
      "Removed garbage .hea file\n",
      "Couldn't write 22_1920Pst\n",
      "Removed garbage .hea file\n",
      "Couldn't write 23_1920Pst\n",
      "Removed garbage .hea file\n",
      "Couldn't write 24_1819Pst\n",
      "Removed garbage .hea file\n",
      "Couldn't write 2_2021Pre\n",
      "Removed garbage .hea file\n",
      "Couldn't write 30_1920Pst\n",
      "Removed garbage .hea file\n",
      "Couldn't write 30_2122Pre\n",
      "Removed garbage .hea file\n",
      "Couldn't write 32_1920Pst\n",
      "Removed garbage .hea file\n",
      "Couldn't write 33_1920Pre\n",
      "Removed garbage .hea file\n",
      "Couldn't parse data\\pf12red\\5 163XML\\35_2122Pre.XML\n",
      "Couldn't write 37_1920Pre\n",
      "Removed garbage .hea file\n",
      "Couldn't write 37_2021Pre\n",
      "Removed garbage .hea file\n",
      "Couldn't write 3_1920Pre\n",
      "Removed garbage .hea file\n",
      "Couldn't write 48_1920Pre\n",
      "Removed garbage .hea file\n",
      "Couldn't write 48_2021Pre\n",
      "Removed garbage .hea file\n",
      "Couldn't write 7_2021Pre\n",
      "Removed garbage .hea file\n"
     ]
    }
   ],
   "source": [
    "for file in pf12red_xml_dir.iterdir():\n",
    "    # Only process XML files\n",
    "    if file.suffix != '.XML':\n",
    "        print(f\"How did {file} get there?\")\n",
    "        continue\n",
    "    \n",
    "    # Attempt to parse XML file using xmltodict package\n",
    "    with open(file, 'rb') as f:\n",
    "        xml_str = f.read().decode('utf8')\n",
    "    try:\n",
    "        xml_dict = xmltodict.parse(xml_str)\n",
    "    except:\n",
    "        print(f\"Couldn't parse {file}\")\n",
    "    \n",
    "    # Extract patient info\n",
    "    age = xml_dict['CardiologyXML']['PatientInfo']['Age']['#text']\n",
    "    gender = xml_dict['CardiologyXML']['PatientInfo']['Gender']\n",
    "\n",
    "    # Extract diagnosis info (save as SNOMED-CT codes)\n",
    "    athlete_id = int(file.stem.split('_')[0])\n",
    "    labels = labels_df[labels_df.AthleteID == athlete_id]\n",
    "    dx_comment = \"Dx: \"\n",
    "    # TODO: What does SR label mean?\n",
    "    # if labels.SR == 'X':\n",
    "    #     dx_comment += \"426783006\"   # Normal sinus rhythm\n",
    "    #     dx_comment += \"427393009\"   # Sinus arrhythmia\n",
    "    if (labels.SB == 'X').item():\n",
    "        dx_comment += \"426177001,\"\n",
    "    if (labels.iRBBB == 'X').item():\n",
    "        dx_comment += \"713426002,\"\n",
    "\n",
    "    # Extract lead waveforms (version 1)\n",
    "    lead_samples = []\n",
    "    for i in range(12):\n",
    "        # sample_str = xml_dict['CardiologyXML']['RestingECGMeasurements']['MedianSamples']['WaveformData'][i]['#text']\n",
    "        sample_str = xml_dict['CardiologyXML']['StripData']['WaveformData'][0]['#text']\n",
    "        sample_list = list(map(int, sample_str.split(',')))\n",
    "        lead_samples.append(np.array(sample_list, dtype=int))\n",
    "    p_signal = np.stack(lead_samples) * 0.005\n",
    "    p_signal= p_signal.transpose()\n",
    "    \n",
    "    # Write new WFDB record\n",
    "    # print(f\"Writing {file.stem}\")\n",
    "    try:\n",
    "        wfdb.wrsamp(\n",
    "            file.stem, \n",
    "            fs=500, \n",
    "            units=['mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV', 'mV'],\n",
    "            sig_name=['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'],\n",
    "            p_signal=p_signal,\n",
    "            comments=[f\"age: {age}\", f\"gender: {gender}\", f\"{dx_comment}\"],\n",
    "            write_dir=pf12red_extracted_dir,\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Couldn't write {file.stem}\")\n",
    "        garbage_record = (pf12red_extracted_dir / file.stem)\n",
    "        if garbage_record.with_suffix('.hea').exists():\n",
    "            garbage_record.with_suffix('.hea').unlink()\n",
    "            print(\"Removed garbage .hea file\")\n",
    "        if garbage_record.with_suffix('.dat').exists():\n",
    "            garbage_record.with_suffix('.dat').unlink()\n",
    "            print(\"Removed garbage .dat file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What should the p_signal look like?\n",
    "norwegian_dataset_dir = data_dir / \"norwegian-athlete-ecg\" / \"1.0.0\"\n",
    "record = wfdb.rdrecord(norwegian_dataset_dir / \"ath_001\")\n",
    "record.p_signal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting waveform from PDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
