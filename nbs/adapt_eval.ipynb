{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Click to see packages imported\"\n",
    "import os\n",
    "import configparser\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is c:\\Users\\Shaun\\source\\Thesis\\MisdiagnosisOfAthleteECG\n"
     ]
    }
   ],
   "source": [
    "#|include: false\n",
    "# If the current working directory is the nbs/ folder, change to the project \n",
    "# root directory instead.\n",
    "if Path.cwd().stem == \"nbs\":\n",
    "    os.chdir(Path.cwd().parent)\n",
    "print(f\"The current working directory is {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.util import get_all_records, codes_to_label_vector, get_predicted_findings\n",
    "from src.data.challenge2020 import extract_snomed_ct_codes_from_comment\n",
    "import src.data.norwegian as norwegian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets are located at C:\\Users\\Shaun\\source\\Thesis\\MisdiagnosisOfAthleteECG\\data\n"
     ]
    }
   ],
   "source": [
    "#|include: false\n",
    "# Import configuration settings, like location of data directory.\n",
    "config = configparser.ConfigParser()\n",
    "if not Path(\"config.ini\").exists():\n",
    "    print(\"WARNING: Please generate a config.ini file by running scripts/get_datasets.py\")\n",
    "else:\n",
    "    config.read(\"config.ini\")\n",
    "    data_dir = Path((config[\"datasets\"][\"path\"])).expanduser()\n",
    "    print(f\"Datasets are located at {data_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinus_labels = [426177001, 426783006, 427084000, 427393009]\n",
    "# sinus_labels = [426177001, 426783006]       # Bradycardia or Normal\n",
    "rbbb_labels = [713427006, 713426002]        # Incomplete RBBB, Complete RBBB\n",
    "# won't do t-wave inversion, because no output for lead number provided.\n",
    "athlete_labels = sinus_labels + rbbb_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = Path.cwd() / \"config\"\n",
    "\n",
    "# Make sure benchmark directory exists\n",
    "benchmark_dir = data_dir / \"benchmark\"\n",
    "if not benchmark_dir.exists():\n",
    "    benchmark_dir.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Change weights_dir directory to run benchmark on different dataset\n",
    "eval_dataset_dir = data_dir / \"pf12red\" / \"extracted\"\n",
    "# eval_dataset_dir = data_dir / \"challenge-2020\" / \"1.0.2\" / \"training\" / \"ptb\" / \"g1\"\n",
    "# eval_dataset_dir = data_dir / \"challenge-2020\" / \"1.0.2\" / \"training\" / \"st_petersburg_incart\" / \"g1\"\n",
    "# eval_dataset_dir = data_dir / \"norwegian-athlete-ecg\" / \"1.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_all_records(eval_dataset_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 12ECG model...\n",
      "Extracting 12ECG features...\n",
      "    1/143...\n",
      "    2/143...\n",
      "    3/143...\n",
      "    4/143...\n",
      "    5/143...\n",
      "    6/143...\n",
      "    7/143...\n",
      "    8/143...\n",
      "    9/143...\n",
      "    10/143...\n",
      "    11/143...\n",
      "    12/143...\n",
      "    13/143...\n",
      "    14/143...\n",
      "    15/143...\n",
      "    16/143...\n",
      "    17/143...\n",
      "    18/143...\n",
      "    19/143...\n",
      "    20/143...\n",
      "    21/143...\n",
      "    22/143...\n",
      "    23/143...\n",
      "    24/143...\n",
      "    25/143...\n",
      "    26/143...\n",
      "    27/143...\n",
      "    28/143...\n",
      "    29/143...\n",
      "    30/143...\n",
      "    31/143...\n",
      "    32/143...\n",
      "    33/143...\n",
      "    34/143...\n",
      "    35/143...\n",
      "    36/143...\n",
      "    37/143...\n",
      "    38/143...\n",
      "    39/143...\n",
      "    40/143...\n",
      "    41/143...\n",
      "    42/143...\n",
      "    43/143...\n",
      "    44/143...\n",
      "    45/143...\n",
      "    46/143...\n",
      "    47/143...\n",
      "    48/143...\n",
      "    49/143...\n",
      "    50/143...\n",
      "    51/143...\n",
      "    52/143...\n",
      "    53/143...\n",
      "    54/143...\n",
      "    55/143...\n",
      "    56/143...\n",
      "    57/143...\n",
      "    58/143...\n",
      "    59/143...\n",
      "    60/143...\n",
      "    61/143...\n",
      "    62/143...\n",
      "    63/143...\n",
      "    64/143...\n",
      "    65/143...\n",
      "    66/143...\n",
      "    67/143...\n",
      "    68/143...\n",
      "    69/143...\n",
      "    70/143...\n",
      "    71/143...\n",
      "    72/143...\n",
      "    73/143...\n",
      "    74/143...\n",
      "    75/143...\n",
      "    76/143...\n",
      "    77/143...\n",
      "    78/143...\n",
      "    79/143...\n",
      "    80/143...\n",
      "    81/143...\n",
      "    82/143...\n",
      "    83/143...\n",
      "    84/143...\n",
      "    85/143...\n",
      "    86/143...\n",
      "    87/143...\n",
      "    88/143...\n",
      "    89/143...\n",
      "    90/143...\n",
      "    91/143...\n",
      "    92/143...\n",
      "    93/143...\n",
      "    94/143...\n",
      "    95/143...\n",
      "    96/143...\n",
      "    97/143...\n",
      "    98/143...\n",
      "    99/143...\n",
      "    100/143...\n",
      "    101/143...\n",
      "    102/143...\n",
      "    103/143...\n",
      "    104/143...\n",
      "    105/143...\n",
      "    106/143...\n",
      "    107/143...\n",
      "    108/143...\n",
      "    109/143...\n",
      "    110/143...\n",
      "    111/143...\n",
      "    112/143...\n",
      "    113/143...\n",
      "    114/143...\n",
      "    115/143...\n",
      "    116/143...\n",
      "    117/143...\n",
      "    118/143...\n",
      "    119/143...\n",
      "    120/143...\n",
      "    121/143...\n",
      "    122/143...\n",
      "    123/143...\n",
      "    124/143...\n",
      "    125/143...\n",
      "    126/143...\n",
      "    127/143...\n",
      "    128/143...\n",
      "    129/143...\n",
      "    130/143...\n",
      "    131/143...\n",
      "    132/143...\n",
      "    133/143...\n",
      "    134/143...\n",
      "    135/143...\n",
      "    136/143...\n",
      "    137/143...\n",
      "    138/143...\n",
      "    139/143...\n",
      "    140/143...\n",
      "    141/143...\n",
      "    142/143...\n",
      "    143/143...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Note: Change weights_dir directory to run benchmark on different model\n",
    "weights_dir = Path.cwd() / \"checkpoints\" / \"finetune_6\"\n",
    "output_dir = benchmark_dir / eval_dataset_dir.parent / weights_dir.stem\n",
    "\n",
    "if output_dir.exists():\n",
    "    print(f\"{output_dir} already exists. Benchmark has already been run.\")\n",
    "else:\n",
    "    # Run benchmark using modified PhysioNet Challenge 2020 driver.py\n",
    "    output_dir.mkdir(parents=True)\n",
    "    !python PhysioNet2020_driver.py {weights_dir} {config_dir} {eval_dataset_dir} {output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classifier_metrics(tn, fp, fn, tp):\n",
    "    P = tp + fn\n",
    "    N = fp + tn\n",
    "    print(\"Population\")\n",
    "    print(\"----------\")\n",
    "    print(f\"Total population: {P+N}\")\n",
    "    print(f\"Positive: {P}\")\n",
    "    print(f\"Negative: {N}\\n\")\n",
    "\n",
    "    acc = (tp + tn) / (P+N)\n",
    "    ppv = tp / (tp + fp)\n",
    "    f1 = 2 * tp / (2*tp + fp + fn)\n",
    "    print(\"Performance\")\n",
    "    print(\"-----------\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Precision: {ppv}\")\n",
    "    print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_confusion = np.zeros((2,2), dtype=int)\n",
    "for entry in get_all_records(eval_dataset_dir):\n",
    "    record = wfdb.rdrecord(eval_dataset_dir / entry)\n",
    "\n",
    "    if eval_dataset_dir == data_dir / \"norwegian-athlete-ecg\" / \"1.0.0\":\n",
    "        # Actual finding labels (norwegian dataset only)\n",
    "        comments_c = record.comments[1]\n",
    "        findings_c = norwegian.extract_findings(comments_c)\n",
    "        actual_findings = norwegian.classify_relevant_findings(findings_c)\n",
    "        actual_labels = codes_to_label_vector(actual_findings, athlete_labels)\n",
    "        actual_scores = np.array(actual_labels, dtype=float)\n",
    "    else:\n",
    "        # Actual finding labels\n",
    "        if record.comments[2] == 'Dx:':\n",
    "            finding_codes = []\n",
    "        else:\n",
    "            finding_codes = extract_snomed_ct_codes_from_comment(record.comments[2])\n",
    "        actual_labels = codes_to_label_vector(finding_codes, athlete_labels)\n",
    "\n",
    "    # Predicted label from model\n",
    "    file = output_dir / (entry+'.csv')\n",
    "    predicted_findings = get_predicted_findings(file)\n",
    "    predicted_labels = codes_to_label_vector(predicted_findings, athlete_labels)\n",
    "\n",
    "    # Hack: If no sinus rhythm findings, assume normal sinus rhythm (426783006)\n",
    "    if sum(actual_labels) == 0:\n",
    "        actual_labels[1] = 1\n",
    "    if sum(predicted_labels) == 0:\n",
    "        predicted_labels[1] = 1\n",
    "    \n",
    "    # Calculate confusion matrix for entry, add to total\n",
    "    total_confusion += confusion_matrix(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[606,  97],\n",
       "       [109,  46]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population\n",
      "----------\n",
      "Total population: 858\n",
      "Positive: 155\n",
      "Negative: 703\n",
      "\n",
      "Performance\n",
      "-----------\n",
      "Accuracy: 0.7599067599067599\n",
      "Precision: 0.32167832167832167\n",
      "F1-Score: 0.3087248322147651\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = total_confusion.ravel()\n",
    "print_classifier_metrics(tn, fp, fn, tp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
