{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning classifier output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaun/source/Thesis/PhysioNetChallenge2020/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Click to see packages imported\"\n",
    "import os\n",
    "import configparser\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import dsail\n",
    "from dsail.model.model_utils import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is /Users/shaun/source/Thesis/PhysioNetChallenge2020\n"
     ]
    }
   ],
   "source": [
    "#|include: false\n",
    "# If the current working directory is the nbs/ folder, change to the project \n",
    "# root directory instead.\n",
    "\n",
    "if Path.cwd().stem == \"nbs\":\n",
    "    os.chdir(Path.cwd().parent)\n",
    "print(f\"The current working directory is {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Click to see local packages imported\"\n",
    "from src.run_12ECG_classifier import load_12ECG_model, run_12ECG_classifier\n",
    "from src.data.util import get_all_records, get_predicted_findings, diagnosis_codes, codes_to_label_vector\n",
    "import src.data.norwegian as norwegian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets are located at /Users/shaun/source/Thesis/PhysioNetChallenge2020/data\n"
     ]
    }
   ],
   "source": [
    "#|include: false\n",
    "# Import configuration settings, like location of data directory.\n",
    "config = configparser.ConfigParser()\n",
    "if not Path(\"config.ini\").exists():\n",
    "    print(\"WARNING: Please generate a config.ini file by running scripts/get_datasets.py\")\n",
    "else:\n",
    "    config.read(\"config.ini\")\n",
    "    data_dir = Path((config[\"datasets\"][\"path\"])).expanduser()\n",
    "    print(f\"Datasets are located at {data_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sinus_labels = [426177001, 426783006, 427084000, 427393009]\n",
    "sinus_labels = [426177001, 426783006]       # Bradycardia or Normal\n",
    "rbbb_labels = [713427006, 713426002]        # Incomplete RBBB, Complete RBBB\n",
    "# won't do t-wave inversion, because no output for lead number provided.\n",
    "athlete_labels = sinus_labels + rbbb_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shaun/source/Thesis/PhysioNetChallenge2020/checkpoints/finetune_1 already exists. Are we overwriting an existing finetune?\n"
     ]
    }
   ],
   "source": [
    "original_weights_dir = Path.cwd() / \"checkpoints\" / \"original\"\n",
    "finetune_dir = Path.cwd() / \"checkpoints\" / \"finetune_1\"\n",
    "\n",
    "config_dir = Path.cwd() / \"config\"\n",
    "training_data_dir = data_dir / \"challenge-2020\" / \"1.0.2\" / \"training\"\n",
    "target_data_dir = data_dir / \"norwegian-athlete-ecg\" / \"1.0.0\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "if finetune_dir.exists():\n",
    "    print(f\"{finetune_dir} already exists. Are we overwriting an existing finetune?\")\n",
    "else:\n",
    "    finetune_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model config from disk\n",
    "data_cfg = dsail.config.DataConfig(config_dir / \"data.json\")\n",
    "preprocess_cfg = dsail.config.PreprocessConfig(config_dir / \"preprocess.json\")\n",
    "model_cfg = dsail.config.ModelConfig(config_dir / \"model.json\")\n",
    "run_cfg = dsail.config.RunConfig(config_dir / \"run.json\")\n",
    "\n",
    "# Check if CUDA device available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from DSAIL_SNU\n",
    "\n",
    "def set_seeds(seed):\n",
    "    \"\"\" set random seeds \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fold in range(10):\n",
    "#     set_seeds(2020)\n",
    "\n",
    "#     # Load data for finetuning and evaluation\n",
    "\n",
    "#     # Initialize model\n",
    "#     model, params = get_model(model_cfg, data_cfg.num_channels, len(data_cfg.scored_classes))\n",
    "\n",
    "#     # Training loop\n",
    "\n",
    "#     # Save network (note that full model is ensemble of 10 networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 12ECG model...\n"
     ]
    }
   ],
   "source": [
    "print('Loading 12ECG model...')\n",
    "model = load_12ECG_model(original_weights_dir, config_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model is an ensemble of 10 networks\n"
     ]
    }
   ],
   "source": [
    "print(f\"This model is an ensemble of {len(model[3])} networks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each classification output, there are weights for 256 inputs to adjust.\n",
    "# Can we use partial backpropogation for this layer only?\n",
    "model[3][0].linear.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, is just adding bias enough?\n",
    "model[3][0].linear.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in get_all_records(target_data_dir):\n",
    "    # 12-lead ECG signals (input data), and header info (e.g. sampling frequency)\n",
    "    record = wfdb.rdrecord(target_data_dir / entry)\n",
    "    signals = record.p_signal.transpose()\n",
    "    with open((target_data_dir / entry).with_suffix(\".hea\"), 'r') as f:\n",
    "        header_data=f.readlines()\n",
    "\n",
    "    # Actual labels from cardiologist\n",
    "    comments_c = record.comments[1]\n",
    "    findings_c = norwegian.extract_findings(comments_c)\n",
    "    actual_findings = norwegian.classify_relevant_findings(findings_c)\n",
    "    actual_labels = codes_to_label_vector(actual_findings, athlete_labels)\n",
    "    actual_scores = np.array(actual_labels, dtype=float)\n",
    "\n",
    "    # Run model, get predictions\n",
    "    current_label, current_score, classes = run_12ECG_classifier(signals, header_data, model)\n",
    "    predicted_scores = np.zeros(len(athlete_labels))\n",
    "    for i, code in enumerate(classes):\n",
    "        if int(code) in athlete_labels:\n",
    "            index = athlete_labels.index(int(code))\n",
    "            predicted_scores[index] = current_score[i]\n",
    "            \n",
    "    # Find error\n",
    "\n",
    "\n",
    "    # Adjust output stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03358536, 0.35342378, 0.59899798, 0.69184965])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "print(np.finfo(float).eps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
